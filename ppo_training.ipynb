{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import EvalCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env = make_vec_env(f'LunarLander{\"Continuous\" if continuous else \"\"}-v2', n_envs=16)\n",
    "eval_env = make_vec_env(f'LunarLander{\"Continuous\" if continuous else \"\"}-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    train_env,\n",
    "    n_steps=1024,\n",
    "    batch_size=64,\n",
    "    gae_lambda=0.98,\n",
    "    gamma=0.999,\n",
    "    n_epochs=4,\n",
    "    ent_coef=0.01,\n",
    "    verbose=1,\n",
    "    tensorboard_log=f'./runs/ppo_lunar{\"continuous\" if continuous else \"\"}_tensorboard/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_callback = EvalCallback(\n",
    "    eval_env,\n",
    "    best_model_save_path=f'./logs/{\"continuous\" if continuous else \"discrete\"}/ppo',\n",
    "    log_path=f'./logs/{\"continuous\" if continuous else \"discrete\"}/ppo',\n",
    "    eval_freq=1000,\n",
    "    n_eval_episodes=10,\n",
    "    deterministic=True,\n",
    "    render=False,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./runs/ppo_lunar_tensorboard/PPO_5\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 94       |\n",
      "|    ep_rew_mean     | -189     |\n",
      "| time/              |          |\n",
      "|    fps             | 4046     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 16384    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 87.7         |\n",
      "|    ep_rew_mean          | -132         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2004         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072095245 |\n",
      "|    clip_fraction        | 0.032        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | -0.000603    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.87e+03     |\n",
      "|    n_updates            | 4            |\n",
      "|    policy_gradient_loss | -0.00472     |\n",
      "|    value_loss           | 5.3e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 92.5        |\n",
      "|    ep_rew_mean          | -128        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1712        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008713517 |\n",
      "|    clip_fraction        | 0.0403      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.00421     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 545         |\n",
      "|    n_updates            | 8           |\n",
      "|    policy_gradient_loss | -0.00448    |\n",
      "|    value_loss           | 1.7e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 96          |\n",
      "|    ep_rew_mean          | -136        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1615        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009474292 |\n",
      "|    clip_fraction        | 0.0536      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | -0.00423    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 438         |\n",
      "|    n_updates            | 12          |\n",
      "|    policy_gradient_loss | -0.00565    |\n",
      "|    value_loss           | 1.09e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 99          |\n",
      "|    ep_rew_mean          | -128        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1508        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013568429 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | -0.00757    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 454         |\n",
      "|    n_updates            | 16          |\n",
      "|    policy_gradient_loss | -0.00812    |\n",
      "|    value_loss           | 1.28e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | -102        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1446        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007694917 |\n",
      "|    clip_fraction        | 0.0457      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.00601     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 207         |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00352    |\n",
      "|    value_loss           | 709         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 122         |\n",
      "|    ep_rew_mean          | -97.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1394        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006470834 |\n",
      "|    clip_fraction        | 0.0253      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.0254      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 432         |\n",
      "|    n_updates            | 24          |\n",
      "|    policy_gradient_loss | -0.00434    |\n",
      "|    value_loss           | 857         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -73.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1382        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007551116 |\n",
      "|    clip_fraction        | 0.0608      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.0562      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 534         |\n",
      "|    n_updates            | 28          |\n",
      "|    policy_gradient_loss | -0.00548    |\n",
      "|    value_loss           | 614         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 107         |\n",
      "|    ep_rew_mean          | -58.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1375        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009450484 |\n",
      "|    clip_fraction        | 0.0832      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.0952      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 370         |\n",
      "|    n_updates            | 32          |\n",
      "|    policy_gradient_loss | -0.00579    |\n",
      "|    value_loss           | 574         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=-123.59 +/- 123.46\n",
      "Episode length: 605.60 +/- 193.33\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 606          |\n",
      "|    mean_reward          | -124         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 160000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063456506 |\n",
      "|    clip_fraction        | 0.0396       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0.109        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 134          |\n",
      "|    n_updates            | 36           |\n",
      "|    policy_gradient_loss | -0.00452     |\n",
      "|    value_loss           | 399          |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 123      |\n",
      "|    ep_rew_mean     | -33.1    |\n",
      "| time/              |          |\n",
      "|    fps             | 1291     |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 126      |\n",
      "|    total_timesteps | 163840   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 123         |\n",
      "|    ep_rew_mean          | -19.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1273        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009694254 |\n",
      "|    clip_fraction        | 0.067       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.211       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 139         |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00571    |\n",
      "|    value_loss           | 418         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 144         |\n",
      "|    ep_rew_mean          | -13.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1249        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 157         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007402377 |\n",
      "|    clip_fraction        | 0.043       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.232       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 211         |\n",
      "|    n_updates            | 44          |\n",
      "|    policy_gradient_loss | -0.00396    |\n",
      "|    value_loss           | 419         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 218         |\n",
      "|    ep_rew_mean          | 1.39        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1224        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 173         |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008203084 |\n",
      "|    clip_fraction        | 0.0661      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.297       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 337         |\n",
      "|    n_updates            | 48          |\n",
      "|    policy_gradient_loss | -0.00373    |\n",
      "|    value_loss           | 471         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 266          |\n",
      "|    ep_rew_mean          | 1.59         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1194         |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 192          |\n",
      "|    total_timesteps      | 229376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084603885 |\n",
      "|    clip_fraction        | 0.0579       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | 0.403        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 136          |\n",
      "|    n_updates            | 52           |\n",
      "|    policy_gradient_loss | -0.00239     |\n",
      "|    value_loss           | 386          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 284          |\n",
      "|    ep_rew_mean          | -1.32        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1156         |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 212          |\n",
      "|    total_timesteps      | 245760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045668175 |\n",
      "|    clip_fraction        | 0.0378       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.21        |\n",
      "|    explained_variance   | 0.447        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 157          |\n",
      "|    n_updates            | 56           |\n",
      "|    policy_gradient_loss | -0.00226     |\n",
      "|    value_loss           | 334          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 374        |\n",
      "|    ep_rew_mean          | 5.54       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1114       |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 235        |\n",
      "|    total_timesteps      | 262144     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00754362 |\n",
      "|    clip_fraction        | 0.0474     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.2       |\n",
      "|    explained_variance   | 0.553      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 80.3       |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.00226   |\n",
      "|    value_loss           | 298        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 449          |\n",
      "|    ep_rew_mean          | 7.35         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1075         |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 258          |\n",
      "|    total_timesteps      | 278528       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067253644 |\n",
      "|    clip_fraction        | 0.0437       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0.74         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 75.3         |\n",
      "|    n_updates            | 64           |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    value_loss           | 175          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 544          |\n",
      "|    ep_rew_mean          | 19           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1047         |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 281          |\n",
      "|    total_timesteps      | 294912       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041966056 |\n",
      "|    clip_fraction        | 0.0238       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0.702        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 74.6         |\n",
      "|    n_updates            | 68           |\n",
      "|    policy_gradient_loss | -0.00133     |\n",
      "|    value_loss           | 230          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 588          |\n",
      "|    ep_rew_mean          | 20.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1027         |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 302          |\n",
      "|    total_timesteps      | 311296       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069110426 |\n",
      "|    clip_fraction        | 0.0531       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0.805        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 87.1         |\n",
      "|    n_updates            | 72           |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    value_loss           | 136          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=320000, episode_reward=9.96 +/- 120.62\n",
      "Episode length: 495.00 +/- 187.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 495         |\n",
      "|    mean_reward          | 9.96        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 320000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004027666 |\n",
      "|    clip_fraction        | 0.017       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.793       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 47.8        |\n",
      "|    n_updates            | 76          |\n",
      "|    policy_gradient_loss | -0.00127    |\n",
      "|    value_loss           | 169         |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 625      |\n",
      "|    ep_rew_mean     | 29.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 992      |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 330      |\n",
      "|    total_timesteps | 327680   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 657         |\n",
      "|    ep_rew_mean          | 39.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 981         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 350         |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005631855 |\n",
      "|    clip_fraction        | 0.0349      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.869       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 63.7        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00118    |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 706         |\n",
      "|    ep_rew_mean          | 48.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 970         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 371         |\n",
      "|    total_timesteps      | 360448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005707765 |\n",
      "|    clip_fraction        | 0.0411      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.867       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 79.4        |\n",
      "|    n_updates            | 84          |\n",
      "|    policy_gradient_loss | -0.000927   |\n",
      "|    value_loss           | 123         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 709         |\n",
      "|    ep_rew_mean          | 55          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 964         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 390         |\n",
      "|    total_timesteps      | 376832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007398377 |\n",
      "|    clip_fraction        | 0.0455      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.897       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.4        |\n",
      "|    n_updates            | 88          |\n",
      "|    policy_gradient_loss | -0.00181    |\n",
      "|    value_loss           | 81.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 761         |\n",
      "|    ep_rew_mean          | 67.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 953         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 412         |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009396569 |\n",
      "|    clip_fraction        | 0.0211      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.892       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 80.4        |\n",
      "|    n_updates            | 92          |\n",
      "|    policy_gradient_loss | -0.00144    |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 770         |\n",
      "|    ep_rew_mean          | 73          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 945         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 433         |\n",
      "|    total_timesteps      | 409600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005743646 |\n",
      "|    clip_fraction        | 0.0369      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 96          |\n",
      "|    policy_gradient_loss | -0.000988   |\n",
      "|    value_loss           | 46.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 775         |\n",
      "|    ep_rew_mean          | 81.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 939         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 453         |\n",
      "|    total_timesteps      | 425984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002566006 |\n",
      "|    clip_fraction        | 0.0144      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00128    |\n",
      "|    value_loss           | 68.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 768          |\n",
      "|    ep_rew_mean          | 82.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 934          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 473          |\n",
      "|    total_timesteps      | 442368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068746144 |\n",
      "|    clip_fraction        | 0.0282       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.14        |\n",
      "|    explained_variance   | 0.897        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 48.9         |\n",
      "|    n_updates            | 104          |\n",
      "|    policy_gradient_loss | -0.00162     |\n",
      "|    value_loss           | 129          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 821          |\n",
      "|    ep_rew_mean          | 93.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 929          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 493          |\n",
      "|    total_timesteps      | 458752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064987736 |\n",
      "|    clip_fraction        | 0.0426       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.11        |\n",
      "|    explained_variance   | 0.938        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 12.6         |\n",
      "|    n_updates            | 108          |\n",
      "|    policy_gradient_loss | -0.00208     |\n",
      "|    value_loss           | 62.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 834         |\n",
      "|    ep_rew_mean          | 96.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 924         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 513         |\n",
      "|    total_timesteps      | 475136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007963945 |\n",
      "|    clip_fraction        | 0.0362      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.81        |\n",
      "|    n_updates            | 112         |\n",
      "|    policy_gradient_loss | -0.000672   |\n",
      "|    value_loss           | 42.6        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=200.63 +/- 17.30\n",
      "Episode length: 586.60 +/- 102.17\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 587          |\n",
      "|    mean_reward          | 201          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 480000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038801813 |\n",
      "|    clip_fraction        | 0.0331       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.31         |\n",
      "|    n_updates            | 116          |\n",
      "|    policy_gradient_loss | -0.00132     |\n",
      "|    value_loss           | 37.5         |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 867      |\n",
      "|    ep_rew_mean     | 103      |\n",
      "| time/              |          |\n",
      "|    fps             | 909      |\n",
      "|    iterations      | 30       |\n",
      "|    time_elapsed    | 540      |\n",
      "|    total_timesteps | 491520   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 889         |\n",
      "|    ep_rew_mean          | 109         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 904         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 561         |\n",
      "|    total_timesteps      | 507904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006858685 |\n",
      "|    clip_fraction        | 0.0286      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.000798   |\n",
      "|    value_loss           | 32.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 935         |\n",
      "|    ep_rew_mean          | 120         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 903         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 580         |\n",
      "|    total_timesteps      | 524288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007271278 |\n",
      "|    clip_fraction        | 0.0576      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.87        |\n",
      "|    n_updates            | 124         |\n",
      "|    policy_gradient_loss | -0.00343    |\n",
      "|    value_loss           | 13.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 934          |\n",
      "|    ep_rew_mean          | 122          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 900          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 600          |\n",
      "|    total_timesteps      | 540672       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041984036 |\n",
      "|    clip_fraction        | 0.0253       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.936        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.15         |\n",
      "|    n_updates            | 128          |\n",
      "|    policy_gradient_loss | -0.000772    |\n",
      "|    value_loss           | 76.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 951          |\n",
      "|    ep_rew_mean          | 128          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 898          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 620          |\n",
      "|    total_timesteps      | 557056       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033393595 |\n",
      "|    clip_fraction        | 0.0302       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.974        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.08         |\n",
      "|    n_updates            | 132          |\n",
      "|    policy_gradient_loss | -0.00154     |\n",
      "|    value_loss           | 34.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 951         |\n",
      "|    ep_rew_mean          | 131         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 894         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 640         |\n",
      "|    total_timesteps      | 573440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004837021 |\n",
      "|    clip_fraction        | 0.0229      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.33        |\n",
      "|    n_updates            | 136         |\n",
      "|    policy_gradient_loss | -0.000537   |\n",
      "|    value_loss           | 12.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 951          |\n",
      "|    ep_rew_mean          | 133          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 893          |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 660          |\n",
      "|    total_timesteps      | 589824       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067747254 |\n",
      "|    clip_fraction        | 0.0281       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7            |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00152     |\n",
      "|    value_loss           | 25.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 951         |\n",
      "|    ep_rew_mean          | 136         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 892         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 679         |\n",
      "|    total_timesteps      | 606208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005324307 |\n",
      "|    clip_fraction        | 0.024       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.992      |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.21        |\n",
      "|    n_updates            | 144         |\n",
      "|    policy_gradient_loss | 0.000192    |\n",
      "|    value_loss           | 9.89        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 968          |\n",
      "|    ep_rew_mean          | 140          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 889          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 699          |\n",
      "|    total_timesteps      | 622592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039104614 |\n",
      "|    clip_fraction        | 0.0378       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.34         |\n",
      "|    n_updates            | 148          |\n",
      "|    policy_gradient_loss | -0.000425    |\n",
      "|    value_loss           | 8.6          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 952          |\n",
      "|    ep_rew_mean          | 139          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 885          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 721          |\n",
      "|    total_timesteps      | 638976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060190773 |\n",
      "|    clip_fraction        | 0.0314       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.98         |\n",
      "|    n_updates            | 152          |\n",
      "|    policy_gradient_loss | -0.000777    |\n",
      "|    value_loss           | 18.1         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=640000, episode_reward=203.22 +/- 25.25\n",
      "Episode length: 507.60 +/- 41.27\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 508         |\n",
      "|    mean_reward          | 203         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 640000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009948054 |\n",
      "|    clip_fraction        | 0.0588      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.993      |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.65        |\n",
      "|    n_updates            | 156         |\n",
      "|    policy_gradient_loss | -0.00119    |\n",
      "|    value_loss           | 32.9        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 960      |\n",
      "|    ep_rew_mean     | 141      |\n",
      "| time/              |          |\n",
      "|    fps             | 878      |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 745      |\n",
      "|    total_timesteps | 655360   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 960          |\n",
      "|    ep_rew_mean          | 142          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 876          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 766          |\n",
      "|    total_timesteps      | 671744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036983173 |\n",
      "|    clip_fraction        | 0.0354       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.974       |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.61         |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00182     |\n",
      "|    value_loss           | 7.47         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 960        |\n",
      "|    ep_rew_mean          | 142        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 874        |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 786        |\n",
      "|    total_timesteps      | 688128     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00409762 |\n",
      "|    clip_fraction        | 0.0414     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.952     |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.62       |\n",
      "|    n_updates            | 164        |\n",
      "|    policy_gradient_loss | -0.00102   |\n",
      "|    value_loss           | 5.68       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 960         |\n",
      "|    ep_rew_mean          | 144         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 874         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 805         |\n",
      "|    total_timesteps      | 704512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004968745 |\n",
      "|    clip_fraction        | 0.0464      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.919      |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.77        |\n",
      "|    n_updates            | 168         |\n",
      "|    policy_gradient_loss | -0.00147    |\n",
      "|    value_loss           | 6.6         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 968          |\n",
      "|    ep_rew_mean          | 149          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 875          |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 823          |\n",
      "|    total_timesteps      | 720896       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038460612 |\n",
      "|    clip_fraction        | 0.03         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.908       |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.58         |\n",
      "|    n_updates            | 172          |\n",
      "|    policy_gradient_loss | 6.03e-05     |\n",
      "|    value_loss           | 5.61         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 996         |\n",
      "|    ep_rew_mean          | 157         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 874         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 842         |\n",
      "|    total_timesteps      | 737280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007683818 |\n",
      "|    clip_fraction        | 0.059       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.862      |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.518       |\n",
      "|    n_updates            | 176         |\n",
      "|    policy_gradient_loss | -0.00177    |\n",
      "|    value_loss           | 4.97        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 996          |\n",
      "|    ep_rew_mean          | 158          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 874          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 862          |\n",
      "|    total_timesteps      | 753664       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034776314 |\n",
      "|    clip_fraction        | 0.0357       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.848       |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.735        |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | 8.88e-05     |\n",
      "|    value_loss           | 28.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 990          |\n",
      "|    ep_rew_mean          | 158          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 873          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 881          |\n",
      "|    total_timesteps      | 770048       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038260922 |\n",
      "|    clip_fraction        | 0.0367       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.893       |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.24         |\n",
      "|    n_updates            | 184          |\n",
      "|    policy_gradient_loss | 2.02e-06     |\n",
      "|    value_loss           | 3.49         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 982         |\n",
      "|    ep_rew_mean          | 158         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 872         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 901         |\n",
      "|    total_timesteps      | 786432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005377735 |\n",
      "|    clip_fraction        | 0.0345      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.872      |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.72        |\n",
      "|    n_updates            | 188         |\n",
      "|    policy_gradient_loss | -0.00101    |\n",
      "|    value_loss           | 26.7        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=246.92 +/- 11.17\n",
      "Episode length: 343.00 +/- 9.86\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 343          |\n",
      "|    mean_reward          | 247          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 800000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025530339 |\n",
      "|    clip_fraction        | 0.0221       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.819       |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.54         |\n",
      "|    n_updates            | 192          |\n",
      "|    policy_gradient_loss | 0.000449     |\n",
      "|    value_loss           | 17.5         |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 974      |\n",
      "|    ep_rew_mean     | 158      |\n",
      "| time/              |          |\n",
      "|    fps             | 870      |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 921      |\n",
      "|    total_timesteps | 802816   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 960         |\n",
      "|    ep_rew_mean          | 157         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 871         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 940         |\n",
      "|    total_timesteps      | 819200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004731944 |\n",
      "|    clip_fraction        | 0.0459      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.85       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.05        |\n",
      "|    n_updates            | 196         |\n",
      "|    policy_gradient_loss | -0.00033    |\n",
      "|    value_loss           | 16.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 964          |\n",
      "|    ep_rew_mean          | 158          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 871          |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 958          |\n",
      "|    total_timesteps      | 835584       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032665287 |\n",
      "|    clip_fraction        | 0.0346       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.843       |\n",
      "|    explained_variance   | 0.969        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 24.6         |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.000871    |\n",
      "|    value_loss           | 51.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 955         |\n",
      "|    ep_rew_mean          | 162         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 871         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 977         |\n",
      "|    total_timesteps      | 851968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004497079 |\n",
      "|    clip_fraction        | 0.0505      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.793      |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.46        |\n",
      "|    n_updates            | 204         |\n",
      "|    policy_gradient_loss | -0.000498   |\n",
      "|    value_loss           | 3.64        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 933          |\n",
      "|    ep_rew_mean          | 173          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 872          |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 995          |\n",
      "|    total_timesteps      | 868352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034375936 |\n",
      "|    clip_fraction        | 0.0198       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.741       |\n",
      "|    explained_variance   | 0.976        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 53.3         |\n",
      "|    n_updates            | 208          |\n",
      "|    policy_gradient_loss | -0.000113    |\n",
      "|    value_loss           | 42.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 856         |\n",
      "|    ep_rew_mean          | 188         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 873         |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 1013        |\n",
      "|    total_timesteps      | 884736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004543312 |\n",
      "|    clip_fraction        | 0.0444      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.667      |\n",
      "|    explained_variance   | 0.916       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 96.5        |\n",
      "|    n_updates            | 212         |\n",
      "|    policy_gradient_loss | -0.0026     |\n",
      "|    value_loss           | 167         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 678          |\n",
      "|    ep_rew_mean          | 221          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 874          |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 1029         |\n",
      "|    total_timesteps      | 901120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049337572 |\n",
      "|    clip_fraction        | 0.0609       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.658       |\n",
      "|    explained_variance   | 0.867        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 256          |\n",
      "|    n_updates            | 216          |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    value_loss           | 298          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 478         |\n",
      "|    ep_rew_mean          | 241         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 877         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 1045        |\n",
      "|    total_timesteps      | 917504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007710191 |\n",
      "|    clip_fraction        | 0.0605      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.655      |\n",
      "|    explained_variance   | 0.772       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 258         |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00397    |\n",
      "|    value_loss           | 454         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 382       |\n",
      "|    ep_rew_mean          | 254       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 880       |\n",
      "|    iterations           | 57        |\n",
      "|    time_elapsed         | 1060      |\n",
      "|    total_timesteps      | 933888    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0049138 |\n",
      "|    clip_fraction        | 0.0409    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.715    |\n",
      "|    explained_variance   | 0.806     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 66.3      |\n",
      "|    n_updates            | 224       |\n",
      "|    policy_gradient_loss | -0.00189  |\n",
      "|    value_loss           | 272       |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 315          |\n",
      "|    ep_rew_mean          | 259          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 883          |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 1075         |\n",
      "|    total_timesteps      | 950272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045766663 |\n",
      "|    clip_fraction        | 0.0485       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.701       |\n",
      "|    explained_variance   | 0.826        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 79.9         |\n",
      "|    n_updates            | 228          |\n",
      "|    policy_gradient_loss | -0.000967    |\n",
      "|    value_loss           | 196          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=960000, episode_reward=260.77 +/- 19.26\n",
      "Episode length: 302.20 +/- 19.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 302         |\n",
      "|    mean_reward          | 261         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 960000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005641596 |\n",
      "|    clip_fraction        | 0.0493      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.749      |\n",
      "|    explained_variance   | 0.795       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 180         |\n",
      "|    n_updates            | 232         |\n",
      "|    policy_gradient_loss | -0.00141    |\n",
      "|    value_loss           | 265         |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 284      |\n",
      "|    ep_rew_mean     | 258      |\n",
      "| time/              |          |\n",
      "|    fps             | 884      |\n",
      "|    iterations      | 59       |\n",
      "|    time_elapsed    | 1092     |\n",
      "|    total_timesteps | 966656   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 278          |\n",
      "|    ep_rew_mean          | 263          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 888          |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 1105         |\n",
      "|    total_timesteps      | 983040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048273075 |\n",
      "|    clip_fraction        | 0.044        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.773       |\n",
      "|    explained_variance   | 0.833        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 47.2         |\n",
      "|    n_updates            | 236          |\n",
      "|    policy_gradient_loss | -0.000115    |\n",
      "|    value_loss           | 157          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 280          |\n",
      "|    ep_rew_mean          | 269          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 892          |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 1119         |\n",
      "|    total_timesteps      | 999424       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045201387 |\n",
      "|    clip_fraction        | 0.0429       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.747       |\n",
      "|    explained_variance   | 0.816        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 20.3         |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | 0.000218     |\n",
      "|    value_loss           | 105          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 292         |\n",
      "|    ep_rew_mean          | 264         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 896         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 1133        |\n",
      "|    total_timesteps      | 1015808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004354804 |\n",
      "|    clip_fraction        | 0.0347      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.744      |\n",
      "|    explained_variance   | 0.898       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.62        |\n",
      "|    n_updates            | 244         |\n",
      "|    policy_gradient_loss | -2.32e-05   |\n",
      "|    value_loss           | 90.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x20f84027910>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=int(1e6), callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'data/policies/LunarLanderf'LunarLander{\"Continuous\" if continuous else \"\"}-v2'-v2#pop#training')\n",
    "del model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
