{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliencanitrot/opt/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32m[I 2022-10-08 20:29:17,025]\u001b[0m A new study created in memory with name: no-name-fc7c1b30-09a6-4765-810a-cf2e88fe643e\u001b[0m\n",
      "/Users/juliencanitrot/opt/miniconda3/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-08 20:29:19,631]\u001b[0m Trial 0 finished with value: 500.0 and parameters: {'gamma': 0.0007415827707315834, 'max_grad_norm': 2.3344868693397762, 'gae_lambda': 0.008729403961766975, 'exponent_n_steps': 6, 'lr': 0.0017950518642776102, 'ent_coef': 1.6124087656990934e-07, 'ortho_init': False, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:29:22,139]\u001b[0m Trial 1 finished with value: 500.0 and parameters: {'gamma': 0.030745055807499456, 'max_grad_norm': 0.7223464037686391, 'gae_lambda': 0.0013421773632395389, 'exponent_n_steps': 8, 'lr': 0.013639642894899533, 'ent_coef': 3.1498651377608986e-07, 'ortho_init': False, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:29:24,719]\u001b[0m Trial 2 finished with value: 9.333333333333334 and parameters: {'gamma': 0.008438520201336397, 'max_grad_norm': 0.9617443170374795, 'gae_lambda': 0.18555590063787938, 'exponent_n_steps': 8, 'lr': 0.9874383104342074, 'ent_coef': 2.436979991508796e-05, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:29:29,272]\u001b[0m Trial 3 finished with value: 500.0 and parameters: {'gamma': 0.007381474212649053, 'max_grad_norm': 2.6266704402586822, 'gae_lambda': 0.19092268515905525, 'exponent_n_steps': 3, 'lr': 0.001495998174987771, 'ent_coef': 3.284913292852249e-08, 'ortho_init': True, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:29:32,044]\u001b[0m Trial 4 finished with value: 500.0 and parameters: {'gamma': 0.00030660724114984003, 'max_grad_norm': 1.3685347187464583, 'gae_lambda': 0.04504864344025756, 'exponent_n_steps': 9, 'lr': 0.001806866978695073, 'ent_coef': 5.930285567222965e-07, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
      "/Users/juliencanitrot/opt/miniconda3/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-08 20:29:49,167]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:29:51,890]\u001b[0m Trial 6 finished with value: 500.0 and parameters: {'gamma': 0.0010778606187398566, 'max_grad_norm': 0.36025529422774305, 'gae_lambda': 0.011395879499513296, 'exponent_n_steps': 5, 'lr': 4.3309819492282066e-05, 'ent_coef': 0.0001410981966152596, 'ortho_init': False, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:29:53,092]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:29:56,896]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:29:58,013]\u001b[0m Trial 9 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:29:59,251]\u001b[0m Trial 10 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:30:01,910]\u001b[0m Trial 11 finished with value: 500.0 and parameters: {'gamma': 0.07514209118557978, 'max_grad_norm': 0.7679123703860231, 'gae_lambda': 0.0010560157926197322, 'exponent_n_steps': 7, 'lr': 0.02515100396037827, 'ent_coef': 3.693065921451179e-07, 'ortho_init': False, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:30:04,358]\u001b[0m Trial 12 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:30:07,136]\u001b[0m Trial 13 finished with value: 500.0 and parameters: {'gamma': 0.021528129885589484, 'max_grad_norm': 1.368586279600259, 'gae_lambda': 0.0011108700292585048, 'exponent_n_steps': 5, 'lr': 0.012488229401410028, 'ent_coef': 3.236235526133381e-06, 'ortho_init': False, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:30:08,227]\u001b[0m Trial 14 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:30:09,596]\u001b[0m Trial 15 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:30:10,772]\u001b[0m Trial 16 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:30:13,932]\u001b[0m Trial 17 finished with value: 500.0 and parameters: {'gamma': 0.0414277680949034, 'max_grad_norm': 1.7075753375130907, 'gae_lambda': 0.0023664444037324707, 'exponent_n_steps': 4, 'lr': 0.00414278852308873, 'ent_coef': 1.4305858047038614e-07, 'ortho_init': False, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:30:15,392]\u001b[0m Trial 18 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:30:17,787]\u001b[0m Trial 19 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:30:20,352]\u001b[0m Trial 20 finished with value: 148.33333333333334 and parameters: {'gamma': 0.0007466574357816679, 'max_grad_norm': 0.5455116266513669, 'gae_lambda': 0.08452082386594957, 'exponent_n_steps': 7, 'lr': 0.006784266323634852, 'ent_coef': 0.00041324145564493856, 'ortho_init': False, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:30:21,867]\u001b[0m Trial 21 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:30:24,100]\u001b[0m Trial 22 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:30:25,631]\u001b[0m Trial 23 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:30:27,155]\u001b[0m Trial 24 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:30:28,469]\u001b[0m Trial 25 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:30:31,444]\u001b[0m Trial 26 finished with value: 500.0 and parameters: {'gamma': 0.010681865548869188, 'max_grad_norm': 0.7424443278053526, 'gae_lambda': 0.018698166089432314, 'exponent_n_steps': 6, 'lr': 0.0005319641367253298, 'ent_coef': 6.441911811153433e-07, 'ortho_init': True, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:30:32,673]\u001b[0m Trial 27 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:30:35,591]\u001b[0m Trial 28 finished with value: 500.0 and parameters: {'gamma': 0.014174795022889635, 'max_grad_norm': 2.191293705900255, 'gae_lambda': 0.02003226534253948, 'exponent_n_steps': 6, 'lr': 0.000901511017655451, 'ent_coef': 6.964741445235191e-07, 'ortho_init': True, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:30:38,492]\u001b[0m Trial 29 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:30:39,800]\u001b[0m Trial 30 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:30:42,674]\u001b[0m Trial 31 finished with value: 417.3333333333333 and parameters: {'gamma': 0.00031897070153949757, 'max_grad_norm': 1.1853219697412927, 'gae_lambda': 0.12886743047030633, 'exponent_n_steps': 9, 'lr': 0.001633136141422783, 'ent_coef': 5.019023999226913e-07, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:30:47,495]\u001b[0m Trial 32 finished with value: 500.0 and parameters: {'gamma': 0.006904302863216346, 'max_grad_norm': 2.1286856769061355, 'gae_lambda': 0.035318606544769475, 'exponent_n_steps': 3, 'lr': 0.002014958014625642, 'ent_coef': 6.191193167887542e-08, 'ortho_init': True, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:30:48,904]\u001b[0m Trial 33 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:30:50,476]\u001b[0m Trial 34 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:30:53,379]\u001b[0m Trial 35 finished with value: 500.0 and parameters: {'gamma': 0.009806172723882515, 'max_grad_norm': 2.1623053549045865, 'gae_lambda': 0.02959104624485526, 'exponent_n_steps': 6, 'lr': 0.0023187947194534585, 'ent_coef': 1.0797181324963953e-06, 'ortho_init': True, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:30:56,432]\u001b[0m Trial 36 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:30:57,663]\u001b[0m Trial 37 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:30:59,854]\u001b[0m Trial 38 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:31:01,404]\u001b[0m Trial 39 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:31:02,922]\u001b[0m Trial 40 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:31:05,528]\u001b[0m Trial 41 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:31:06,886]\u001b[0m Trial 42 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:31:08,389]\u001b[0m Trial 43 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:31:10,401]\u001b[0m Trial 44 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:31:13,653]\u001b[0m Trial 45 finished with value: 346.6666666666667 and parameters: {'gamma': 0.005614322522339272, 'max_grad_norm': 1.4918498529418691, 'gae_lambda': 0.028814850483278334, 'exponent_n_steps': 4, 'lr': 0.003814337953234682, 'ent_coef': 1.1698978071703152e-06, 'ortho_init': False, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:31:15,068]\u001b[0m Trial 46 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:31:16,208]\u001b[0m Trial 47 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:31:17,508]\u001b[0m Trial 48 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:31:20,390]\u001b[0m Trial 49 finished with value: 500.0 and parameters: {'gamma': 0.024464538199766364, 'max_grad_norm': 1.8984922312288701, 'gae_lambda': 0.0012470222008008334, 'exponent_n_steps': 5, 'lr': 0.0025682569072814966, 'ent_coef': 1.9590622320829453e-07, 'ortho_init': True, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:31:21,817]\u001b[0m Trial 50 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:31:23,112]\u001b[0m Trial 51 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:31:24,685]\u001b[0m Trial 52 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:31:28,735]\u001b[0m Trial 53 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:31:30,102]\u001b[0m Trial 54 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:31:31,585]\u001b[0m Trial 55 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:31:33,228]\u001b[0m Trial 56 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:31:34,702]\u001b[0m Trial 57 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:31:38,049]\u001b[0m Trial 58 finished with value: 500.0 and parameters: {'gamma': 0.02308878903229621, 'max_grad_norm': 1.803621577266175, 'gae_lambda': 0.016016884317150547, 'exponent_n_steps': 6, 'lr': 0.007243740663508607, 'ent_coef': 2.347233960766459e-08, 'ortho_init': True, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:31:39,490]\u001b[0m Trial 59 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:31:40,743]\u001b[0m Trial 60 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:31:42,176]\u001b[0m Trial 61 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:31:43,582]\u001b[0m Trial 62 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:31:44,896]\u001b[0m Trial 63 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:31:47,443]\u001b[0m Trial 64 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:31:50,448]\u001b[0m Trial 65 finished with value: 500.0 and parameters: {'gamma': 0.022596120356495063, 'max_grad_norm': 1.7040055897530995, 'gae_lambda': 0.014371840059157611, 'exponent_n_steps': 6, 'lr': 0.005452761910854019, 'ent_coef': 1.728528093764018e-07, 'ortho_init': True, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:31:51,909]\u001b[0m Trial 66 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:31:54,251]\u001b[0m Trial 67 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:31:57,469]\u001b[0m Trial 68 finished with value: 148.33333333333334 and parameters: {'gamma': 0.015558223692853998, 'max_grad_norm': 1.4897515563527084, 'gae_lambda': 0.001240847931372377, 'exponent_n_steps': 5, 'lr': 0.0006743405320522628, 'ent_coef': 2.4618980011920367e-06, 'ortho_init': True, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:31:58,872]\u001b[0m Trial 69 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:32:00,109]\u001b[0m Trial 70 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:32:03,135]\u001b[0m Trial 71 finished with value: 500.0 and parameters: {'gamma': 0.022887328079008618, 'max_grad_norm': 1.6959233010124692, 'gae_lambda': 0.01421292302827205, 'exponent_n_steps': 6, 'lr': 0.005223190800668852, 'ent_coef': 1.7243054919145416e-07, 'ortho_init': True, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:32:04,618]\u001b[0m Trial 72 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:32:06,351]\u001b[0m Trial 73 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:32:09,695]\u001b[0m Trial 74 finished with value: 500.0 and parameters: {'gamma': 0.07611787999028867, 'max_grad_norm': 1.959602788403857, 'gae_lambda': 0.0011469149108190903, 'exponent_n_steps': 4, 'lr': 0.002402482869129322, 'ent_coef': 4.1366485088843764e-07, 'ortho_init': False, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:32:11,089]\u001b[0m Trial 75 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:32:12,663]\u001b[0m Trial 76 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:32:14,134]\u001b[0m Trial 77 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:32:17,201]\u001b[0m Trial 78 finished with value: 500.0 and parameters: {'gamma': 0.025666105567395993, 'max_grad_norm': 1.4104943629583513, 'gae_lambda': 0.0017845147506998593, 'exponent_n_steps': 7, 'lr': 0.010551376595314216, 'ent_coef': 1.2337042016748807e-07, 'ortho_init': False, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:32:20,080]\u001b[0m Trial 79 finished with value: 135.33333333333334 and parameters: {'gamma': 0.08853234156279852, 'max_grad_norm': 1.9617479142746892, 'gae_lambda': 0.006867948297624074, 'exponent_n_steps': 6, 'lr': 0.0024758561858890605, 'ent_coef': 4.3346469759807205e-08, 'ortho_init': True, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:32:21,431]\u001b[0m Trial 80 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:32:22,839]\u001b[0m Trial 81 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:32:25,105]\u001b[0m Trial 82 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:32:26,518]\u001b[0m Trial 83 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:32:27,826]\u001b[0m Trial 84 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:32:29,432]\u001b[0m Trial 85 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:32:30,761]\u001b[0m Trial 86 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:32:32,325]\u001b[0m Trial 87 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:32:33,559]\u001b[0m Trial 88 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:32:34,981]\u001b[0m Trial 89 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:32:36,247]\u001b[0m Trial 90 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:32:37,568]\u001b[0m Trial 91 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:32:38,875]\u001b[0m Trial 92 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:32:41,153]\u001b[0m Trial 93 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:32:42,709]\u001b[0m Trial 94 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:32:45,754]\u001b[0m Trial 95 finished with value: 500.0 and parameters: {'gamma': 0.018698059745539338, 'max_grad_norm': 2.332578976848716, 'gae_lambda': 0.012577157580838442, 'exponent_n_steps': 6, 'lr': 0.005239291002889482, 'ent_coef': 2.1751384708189705e-07, 'ortho_init': True, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:32:47,327]\u001b[0m Trial 96 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:32:48,973]\u001b[0m Trial 97 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:32:50,561]\u001b[0m Trial 98 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-10-08 20:32:51,968]\u001b[0m Trial 99 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials:  100\n",
      "Best trial:\n",
      "  Value:  500.0\n",
      "  Params: \n",
      "    gamma: 0.0007415827707315834\n",
      "    max_grad_norm: 2.3344868693397762\n",
      "    gae_lambda: 0.008729403961766975\n",
      "    exponent_n_steps: 6\n",
      "    lr: 0.0017950518642776102\n",
      "    ent_coef: 1.6124087656990934e-07\n",
      "    ortho_init: False\n",
      "    net_arch: tiny\n",
      "    activation_fn: tanh\n",
      "  User attrs:\n",
      "    gamma_: 0.9992584172292684\n",
      "    gae_lambda_: 0.991270596038233\n",
      "    n_steps: 64\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Optuna example that optimizes the hyperparameters of\n",
    "a reinforcement learning agent using A2C implementation from Stable-Baselines3\n",
    "on a OpenAI Gym environment.\n",
    "This is a simplified version of what can be found in https://github.com/DLR-RM/rl-baselines3-zoo.\n",
    "You can run this example as follows:\n",
    "    $ python sb3_simple.py\n",
    "\"\"\"\n",
    "from typing import Any\n",
    "from typing import Dict\n",
    "\n",
    "import gym\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "N_TRIALS = 100\n",
    "N_STARTUP_TRIALS = 5\n",
    "N_EVALUATIONS = 2\n",
    "N_TIMESTEPS = int(1e6)\n",
    "EVAL_FREQ = int(N_TIMESTEPS / N_EVALUATIONS)\n",
    "N_EVAL_EPISODES = 3\n",
    "\n",
    "ENV_ID = \"LunarLander-v2\"\n",
    "\n",
    "DEFAULT_HYPERPARAMS = {\n",
    "    \"policy\": \"MlpPolicy\",\n",
    "    \"env\": ENV_ID,\n",
    "}\n",
    "\n",
    "\n",
    "def sample_ppo_params(trial: optuna.Trial) -> Dict[str, Any]:\n",
    "    \"\"\"Sampler for PPO hyperparameters.\"\"\"\n",
    "    n_steps = 2 ** trial.suggest_int(\"exponent_n_steps\", 7, 11)\n",
    "    gae_lambda = 1.0 - trial.suggest_float(\"gae_lambda\", 0.001, 0.2, log=True)\n",
    "    gamma = 1.0 - trial.suggest_float(\"gamma\", 0.0001, 0.1, log=True)\n",
    "    n_epochs = trial.suggest_categorical(\"n_epochs\", [4, 10, 20])\n",
    "    ent_coef = trial.suggest_float(\"ent_coef\", 0.001, 0.1, log=True)\n",
    "\n",
    "    # Display true values\n",
    "    trial.set_user_attr(\"gamma_\", gamma)\n",
    "    trial.set_user_attr(\"gae_lambda_\", gae_lambda)\n",
    "    trial.set_user_attr(\"n_steps\", n_steps)\n",
    "\n",
    "    net_arch = [\n",
    "        {\"pi\": [64], \"vf\": [64]}\n",
    "        if net_arch == \"tiny\"\n",
    "        else {\"pi\": [64, 64], \"vf\": [64, 64]}\n",
    "    ]\n",
    "\n",
    "    activation_fn = {\"tanh\": nn.Tanh, \"relu\": nn.ReLU}[activation_fn]\n",
    "\n",
    "    return {\n",
    "        \"n_steps\": n_steps,\n",
    "        \"gae_lambda\": gae_lambda,\n",
    "        \"gamma\": gamma,\n",
    "        \"n_epochs\": n_epochs,\n",
    "        \"ent_coef\": ent_coef,\n",
    "    }\n",
    "\n",
    "\n",
    "class TrialEvalCallback(EvalCallback):\n",
    "    \"\"\"Callback used for evaluating and reporting a trial.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        eval_env: gym.Env,\n",
    "        trial: optuna.Trial,\n",
    "        n_eval_episodes: int = 5,\n",
    "        eval_freq: int = 10000,\n",
    "        deterministic: bool = True,\n",
    "        verbose: int = 0,\n",
    "    ):\n",
    "\n",
    "        super().__init__(\n",
    "            eval_env=eval_env,\n",
    "            n_eval_episodes=n_eval_episodes,\n",
    "            eval_freq=eval_freq,\n",
    "            deterministic=deterministic,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        self.trial = trial\n",
    "        self.eval_idx = 0\n",
    "        self.is_pruned = False\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.eval_freq > 0 and self.n_calls % self.eval_freq == 0:\n",
    "            super()._on_step()\n",
    "            self.eval_idx += 1\n",
    "            self.trial.report(self.last_mean_reward, self.eval_idx)\n",
    "            # Prune trial if need\n",
    "            if self.trial.should_prune():\n",
    "                self.is_pruned = True\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "\n",
    "    kwargs = DEFAULT_HYPERPARAMS.copy()\n",
    "    # Sample hyperparameters\n",
    "    kwargs.update(sample_ppo_params(trial))\n",
    "    # Create the RL model\n",
    "    model = PPO(**kwargs)\n",
    "    # Create env used for evaluation\n",
    "    eval_env = gym.make(ENV_ID)\n",
    "    # Create the callback that will periodically evaluate\n",
    "    # and report the performance\n",
    "    eval_callback = TrialEvalCallback(\n",
    "        eval_env,\n",
    "        trial,\n",
    "        n_eval_episodes=N_EVAL_EPISODES,\n",
    "        eval_freq=EVAL_FREQ,\n",
    "        deterministic=True,\n",
    "    )\n",
    "\n",
    "    nan_encountered = False\n",
    "    try:\n",
    "        model.learn(N_TIMESTEPS, callback=eval_callback)\n",
    "    except AssertionError as e:\n",
    "        # Sometimes, random hyperparams can generate NaN\n",
    "        print(e)\n",
    "        nan_encountered = True\n",
    "    finally:\n",
    "        # Free memory\n",
    "        model.env.close()\n",
    "        eval_env.close()\n",
    "\n",
    "    # Tell the optimizer that the trial failed\n",
    "    if nan_encountered:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    if eval_callback.is_pruned:\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return eval_callback.last_mean_reward\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set pytorch num threads to 1 for faster training\n",
    "    torch.set_num_threads(1)\n",
    "\n",
    "    sampler = TPESampler(n_startup_trials=N_STARTUP_TRIALS)\n",
    "    # Do not prune before 1/3 of the max budget is used\n",
    "    pruner = MedianPruner(\n",
    "        n_startup_trials=N_STARTUP_TRIALS, n_warmup_steps=N_EVALUATIONS // 3\n",
    "    )\n",
    "\n",
    "    study = optuna.create_study(sampler=sampler, pruner=pruner, direction=\"maximize\")\n",
    "    try:\n",
    "        study.optimize(objective, n_trials=N_TRIALS, timeout=600)\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "    print(\"Number of finished trials: \", len(study.trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    print(\"  User attrs:\")\n",
    "    for key, value in trial.user_attrs.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
