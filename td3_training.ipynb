{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "from stable_baselines3 import TD3\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import EvalCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env = gym.make(\"LunarLanderContinuous-v2\")\n",
    "eval_env = gym.make(\"LunarLanderContinuous-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = TD3(\n",
    "    \"MlpPolicy\",\n",
    "    train_env,\n",
    "    gamma=0.98,\n",
    "    buffer_size=200000,\n",
    "    learning_starts=10000,\n",
    "    gradient_steps=-1,\n",
    "    train_freq=(1, \"episode\"),\n",
    "    learning_rate=1e-3,\n",
    "    policy_kwargs=dict(net_arch=[400, 300]),\n",
    "    verbose=1,\n",
    "    tensorboard_log=\"./runs/td3_lunarcontinuous_tensorboard/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_callback = EvalCallback(\n",
    "    eval_env,\n",
    "    best_model_save_path=\"./logs/continuous/td3\",\n",
    "    log_path=\"./logs/continuous/td3\",\n",
    "    eval_freq=3e4,\n",
    "    n_eval_episodes=10,\n",
    "    deterministic=True,\n",
    "    render=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./runs/td3_lunarcontinuous_tensorboard/TD3_1\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 98.8     |\n",
      "|    ep_rew_mean     | -174     |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 3405     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 395      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 104      |\n",
      "|    ep_rew_mean     | -202     |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 3460     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 834      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 101      |\n",
      "|    ep_rew_mean     | -172     |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 3382     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 1211     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 97.8     |\n",
      "|    ep_rew_mean     | -184     |\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 3405     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 1565     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 98.8     |\n",
      "|    ep_rew_mean     | -178     |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 3401     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 1977     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 97.8     |\n",
      "|    ep_rew_mean     | -175     |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 3439     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2348     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 99.7     |\n",
      "|    ep_rew_mean     | -191     |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 3448     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2792     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 99.8     |\n",
      "|    ep_rew_mean     | -187     |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 3429     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 3193     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 103      |\n",
      "|    ep_rew_mean     | -189     |\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 3390     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 3716     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 105      |\n",
      "|    ep_rew_mean     | -199     |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 3349     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 4213     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 106      |\n",
      "|    ep_rew_mean     | -212     |\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 3348     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 4653     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 104      |\n",
      "|    ep_rew_mean     | -208     |\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 3377     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 5015     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 106      |\n",
      "|    ep_rew_mean     | -202     |\n",
      "| time/              |          |\n",
      "|    episodes        | 52       |\n",
      "|    fps             | 3402     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 5490     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 104      |\n",
      "|    ep_rew_mean     | -202     |\n",
      "| time/              |          |\n",
      "|    episodes        | 56       |\n",
      "|    fps             | 3425     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 5839     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 104      |\n",
      "|    ep_rew_mean     | -204     |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 3446     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 6226     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 104      |\n",
      "|    ep_rew_mean     | -204     |\n",
      "| time/              |          |\n",
      "|    episodes        | 64       |\n",
      "|    fps             | 3456     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 6637     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 104      |\n",
      "|    ep_rew_mean     | -206     |\n",
      "| time/              |          |\n",
      "|    episodes        | 68       |\n",
      "|    fps             | 3456     |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 7039     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 104      |\n",
      "|    ep_rew_mean     | -209     |\n",
      "| time/              |          |\n",
      "|    episodes        | 72       |\n",
      "|    fps             | 3465     |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 7454     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 104      |\n",
      "|    ep_rew_mean     | -211     |\n",
      "| time/              |          |\n",
      "|    episodes        | 76       |\n",
      "|    fps             | 3426     |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 7886     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 105      |\n",
      "|    ep_rew_mean     | -208     |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 3358     |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 8374     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 106      |\n",
      "|    ep_rew_mean     | -211     |\n",
      "| time/              |          |\n",
      "|    episodes        | 84       |\n",
      "|    fps             | 3333     |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 8874     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 106      |\n",
      "|    ep_rew_mean     | -212     |\n",
      "| time/              |          |\n",
      "|    episodes        | 88       |\n",
      "|    fps             | 3323     |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 9331     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 106      |\n",
      "|    ep_rew_mean     | -213     |\n",
      "| time/              |          |\n",
      "|    episodes        | 92       |\n",
      "|    fps             | 3325     |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 9728     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 106      |\n",
      "|    ep_rew_mean     | -209     |\n",
      "| time/              |          |\n",
      "|    episodes        | 96       |\n",
      "|    fps             | 1647     |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 10210    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.69     |\n",
      "|    critic_loss     | 174      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 148      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 112      |\n",
      "|    ep_rew_mean     | -224     |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 756      |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 11187    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.33     |\n",
      "|    critic_loss     | 104      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 997      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 116      |\n",
      "|    ep_rew_mean     | -228     |\n",
      "| time/              |          |\n",
      "|    episodes        | 104      |\n",
      "|    fps             | 554      |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 11957    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.58     |\n",
      "|    critic_loss     | 67.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1674     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 146      |\n",
      "|    ep_rew_mean     | -224     |\n",
      "| time/              |          |\n",
      "|    episodes        | 108      |\n",
      "|    fps             | 262      |\n",
      "|    time_elapsed    | 58       |\n",
      "|    total_timesteps | 15416    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.763   |\n",
      "|    critic_loss     | 55.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 4989     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 162      |\n",
      "|    ep_rew_mean     | -223     |\n",
      "| time/              |          |\n",
      "|    episodes        | 112      |\n",
      "|    fps             | 218      |\n",
      "|    time_elapsed    | 79       |\n",
      "|    total_timesteps | 17411    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.21    |\n",
      "|    critic_loss     | 48.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 7115     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 189      |\n",
      "|    ep_rew_mean     | -216     |\n",
      "| time/              |          |\n",
      "|    episodes        | 116      |\n",
      "|    fps             | 187      |\n",
      "|    time_elapsed    | 109      |\n",
      "|    total_timesteps | 20469    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.48    |\n",
      "|    critic_loss     | 51.3     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 9867     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 213      |\n",
      "|    ep_rew_mean     | -215     |\n",
      "| time/              |          |\n",
      "|    episodes        | 120      |\n",
      "|    fps             | 165      |\n",
      "|    time_elapsed    | 140      |\n",
      "|    total_timesteps | 23302    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.88    |\n",
      "|    critic_loss     | 46.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 12742    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 234      |\n",
      "|    ep_rew_mean     | -209     |\n",
      "| time/              |          |\n",
      "|    episodes        | 124      |\n",
      "|    fps             | 155      |\n",
      "|    time_elapsed    | 165      |\n",
      "|    total_timesteps | 25734    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.1     |\n",
      "|    critic_loss     | 44.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 15013    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 245      |\n",
      "|    ep_rew_mean     | -198     |\n",
      "| time/              |          |\n",
      "|    episodes        | 128      |\n",
      "|    fps             | 149      |\n",
      "|    time_elapsed    | 181      |\n",
      "|    total_timesteps | 27247    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.34    |\n",
      "|    critic_loss     | 34.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 16670    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jules Dubreuil\\AppData\\Roaming\\Python\\Python310\\site-packages\\stable_baselines3\\common\\evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=30000, episode_reward=-54.53 +/- 52.62\n",
      "Episode length: 787.10 +/- 311.50\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 787      |\n",
      "|    mean_reward     | -54.5    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 30000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.1    |\n",
      "|    critic_loss     | 32.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 19953    |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 276      |\n",
      "|    ep_rew_mean     | -197     |\n",
      "| time/              |          |\n",
      "|    episodes        | 132      |\n",
      "|    fps             | 126      |\n",
      "|    time_elapsed    | 243      |\n",
      "|    total_timesteps | 30743    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 299      |\n",
      "|    ep_rew_mean     | -187     |\n",
      "| time/              |          |\n",
      "|    episodes        | 136      |\n",
      "|    fps             | 123      |\n",
      "|    time_elapsed    | 272      |\n",
      "|    total_timesteps | 33582    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.5    |\n",
      "|    critic_loss     | 29       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 22660    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 321      |\n",
      "|    ep_rew_mean     | -175     |\n",
      "| time/              |          |\n",
      "|    episodes        | 140      |\n",
      "|    fps             | 119      |\n",
      "|    time_elapsed    | 304      |\n",
      "|    total_timesteps | 36304    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.2    |\n",
      "|    critic_loss     | 23.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 25382    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 354      |\n",
      "|    ep_rew_mean     | -164     |\n",
      "| time/              |          |\n",
      "|    episodes        | 144      |\n",
      "|    fps             | 113      |\n",
      "|    time_elapsed    | 351      |\n",
      "|    total_timesteps | 40023    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.94    |\n",
      "|    critic_loss     | 23.8     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 29382    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 366      |\n",
      "|    ep_rew_mean     | -169     |\n",
      "| time/              |          |\n",
      "|    episodes        | 148      |\n",
      "|    fps             | 112      |\n",
      "|    time_elapsed    | 371      |\n",
      "|    total_timesteps | 41642    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.44    |\n",
      "|    critic_loss     | 20.8     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 31332    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 393      |\n",
      "|    ep_rew_mean     | -169     |\n",
      "| time/              |          |\n",
      "|    episodes        | 152      |\n",
      "|    fps             | 110      |\n",
      "|    time_elapsed    | 404      |\n",
      "|    total_timesteps | 44807    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.23    |\n",
      "|    critic_loss     | 19.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 33885    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 426      |\n",
      "|    ep_rew_mean     | -168     |\n",
      "| time/              |          |\n",
      "|    episodes        | 156      |\n",
      "|    fps             | 109      |\n",
      "|    time_elapsed    | 442      |\n",
      "|    total_timesteps | 48392    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.26    |\n",
      "|    critic_loss     | 20.8     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 37470    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 462      |\n",
      "|    ep_rew_mean     | -160     |\n",
      "| time/              |          |\n",
      "|    episodes        | 160      |\n",
      "|    fps             | 107      |\n",
      "|    time_elapsed    | 486      |\n",
      "|    total_timesteps | 52392    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.84    |\n",
      "|    critic_loss     | 23.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 41470    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 482      |\n",
      "|    ep_rew_mean     | -154     |\n",
      "| time/              |          |\n",
      "|    episodes        | 164      |\n",
      "|    fps             | 105      |\n",
      "|    time_elapsed    | 517      |\n",
      "|    total_timesteps | 54831    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.94    |\n",
      "|    critic_loss     | 20       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 44562    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 504      |\n",
      "|    ep_rew_mean     | -148     |\n",
      "| time/              |          |\n",
      "|    episodes        | 168      |\n",
      "|    fps             | 105      |\n",
      "|    time_elapsed    | 543      |\n",
      "|    total_timesteps | 57423    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.54    |\n",
      "|    critic_loss     | 23.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 47094    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-3.50 +/- 87.22\n",
      "Episode length: 841.20 +/- 318.85\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 841      |\n",
      "|    mean_reward     | -3.5     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 60000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.11    |\n",
      "|    critic_loss     | 18.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 50072    |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 535      |\n",
      "|    ep_rew_mean     | -141     |\n",
      "| time/              |          |\n",
      "|    episodes        | 172      |\n",
      "|    fps             | 102      |\n",
      "|    time_elapsed    | 596      |\n",
      "|    total_timesteps | 60994    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 547      |\n",
      "|    ep_rew_mean     | -132     |\n",
      "| time/              |          |\n",
      "|    episodes        | 176      |\n",
      "|    fps             | 100      |\n",
      "|    time_elapsed    | 620      |\n",
      "|    total_timesteps | 62544    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.594   |\n",
      "|    critic_loss     | 24.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 52496    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 566      |\n",
      "|    ep_rew_mean     | -129     |\n",
      "| time/              |          |\n",
      "|    episodes        | 180      |\n",
      "|    fps             | 101      |\n",
      "|    time_elapsed    | 638      |\n",
      "|    total_timesteps | 64954    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0241   |\n",
      "|    critic_loss     | 29.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 54032    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 579      |\n",
      "|    ep_rew_mean     | -122     |\n",
      "| time/              |          |\n",
      "|    episodes        | 184      |\n",
      "|    fps             | 101      |\n",
      "|    time_elapsed    | 658      |\n",
      "|    total_timesteps | 66820    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.07     |\n",
      "|    critic_loss     | 17.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 55898    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 615      |\n",
      "|    ep_rew_mean     | -114     |\n",
      "| time/              |          |\n",
      "|    episodes        | 188      |\n",
      "|    fps             | 100      |\n",
      "|    time_elapsed    | 703      |\n",
      "|    total_timesteps | 70820    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.97     |\n",
      "|    critic_loss     | 16.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 59898    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 644      |\n",
      "|    ep_rew_mean     | -108     |\n",
      "| time/              |          |\n",
      "|    episodes        | 192      |\n",
      "|    fps             | 99       |\n",
      "|    time_elapsed    | 746      |\n",
      "|    total_timesteps | 74176    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.14     |\n",
      "|    critic_loss     | 16.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 63898    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 664      |\n",
      "|    ep_rew_mean     | -108     |\n",
      "| time/              |          |\n",
      "|    episodes        | 196      |\n",
      "|    fps             | 100      |\n",
      "|    time_elapsed    | 766      |\n",
      "|    total_timesteps | 76604    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.07     |\n",
      "|    critic_loss     | 15.8     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 65682    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 680      |\n",
      "|    ep_rew_mean     | -86.1    |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 98       |\n",
      "|    time_elapsed    | 800      |\n",
      "|    total_timesteps | 79147    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.94     |\n",
      "|    critic_loss     | 14.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 68976    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 699      |\n",
      "|    ep_rew_mean     | -76.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 204      |\n",
      "|    fps             | 99       |\n",
      "|    time_elapsed    | 824      |\n",
      "|    total_timesteps | 81816    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 6.06     |\n",
      "|    critic_loss     | 15.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 71245    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 686      |\n",
      "|    ep_rew_mean     | -75.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 208      |\n",
      "|    fps             | 98       |\n",
      "|    time_elapsed    | 852      |\n",
      "|    total_timesteps | 84048    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.68     |\n",
      "|    critic_loss     | 14.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 73822    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 682      |\n",
      "|    ep_rew_mean     | -74.1    |\n",
      "| time/              |          |\n",
      "|    episodes        | 212      |\n",
      "|    fps             | 98       |\n",
      "|    time_elapsed    | 869      |\n",
      "|    total_timesteps | 85595    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.04     |\n",
      "|    critic_loss     | 18.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 75341    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 674      |\n",
      "|    ep_rew_mean     | -71.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 216      |\n",
      "|    fps             | 98       |\n",
      "|    time_elapsed    | 889      |\n",
      "|    total_timesteps | 87832    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.59     |\n",
      "|    critic_loss     | 14.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 77345    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=-107.57 +/- 128.54\n",
      "Episode length: 901.00 +/- 136.89\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 901      |\n",
      "|    mean_reward     | -108     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 90000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.33     |\n",
      "|    critic_loss     | 17.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 79922    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 675      |\n",
      "|    ep_rew_mean     | -66.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 220      |\n",
      "|    fps             | 96       |\n",
      "|    time_elapsed    | 938      |\n",
      "|    total_timesteps | 90844    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 679      |\n",
      "|    ep_rew_mean     | -65.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 224      |\n",
      "|    fps             | 96       |\n",
      "|    time_elapsed    | 974      |\n",
      "|    total_timesteps | 93636    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.59     |\n",
      "|    critic_loss     | 20.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 83422    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 686      |\n",
      "|    ep_rew_mean     | -70.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 228      |\n",
      "|    fps             | 96       |\n",
      "|    time_elapsed    | 996      |\n",
      "|    total_timesteps | 95866    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.87     |\n",
      "|    critic_loss     | 12.3     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 85589    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 682      |\n",
      "|    ep_rew_mean     | -66.7    |\n",
      "| time/              |          |\n",
      "|    episodes        | 232      |\n",
      "|    fps             | 96       |\n",
      "|    time_elapsed    | 1027     |\n",
      "|    total_timesteps | 98896    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.49     |\n",
      "|    critic_loss     | 17.3     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 88477    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 693      |\n",
      "|    ep_rew_mean     | -71.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 236      |\n",
      "|    fps             | 96       |\n",
      "|    time_elapsed    | 1066     |\n",
      "|    total_timesteps | 102896   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.58     |\n",
      "|    critic_loss     | 16.8     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 91974    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 699      |\n",
      "|    ep_rew_mean     | -73.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 240      |\n",
      "|    fps             | 96       |\n",
      "|    time_elapsed    | 1102     |\n",
      "|    total_timesteps | 106191   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.07     |\n",
      "|    critic_loss     | 14.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 95269    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 697      |\n",
      "|    ep_rew_mean     | -70      |\n",
      "| time/              |          |\n",
      "|    episodes        | 244      |\n",
      "|    fps             | 96       |\n",
      "|    time_elapsed    | 1141     |\n",
      "|    total_timesteps | 109732   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.32     |\n",
      "|    critic_loss     | 15.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 98810    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39mlearn(total_timesteps\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m(\u001b[39m3e5\u001b[39m), callback\u001b[39m=\u001b[39meval_callback)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\stable_baselines3\\td3\\td3.py:222\u001b[0m, in \u001b[0;36mTD3.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[0;32m    210\u001b[0m     \u001b[39mself\u001b[39m: TD3Self,\n\u001b[0;32m    211\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    219\u001b[0m     reset_num_timesteps: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    220\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m TD3Self:\n\u001b[1;32m--> 222\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mlearn(\n\u001b[0;32m    223\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[0;32m    224\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[0;32m    225\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[0;32m    226\u001b[0m         eval_env\u001b[39m=\u001b[39;49meval_env,\n\u001b[0;32m    227\u001b[0m         eval_freq\u001b[39m=\u001b[39;49meval_freq,\n\u001b[0;32m    228\u001b[0m         n_eval_episodes\u001b[39m=\u001b[39;49mn_eval_episodes,\n\u001b[0;32m    229\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[0;32m    230\u001b[0m         eval_log_path\u001b[39m=\u001b[39;49meval_log_path,\n\u001b[0;32m    231\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[0;32m    232\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:369\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[0;32m    367\u001b[0m         \u001b[39m# Special case when the user passes `gradient_steps=0`\u001b[39;00m\n\u001b[0;32m    368\u001b[0m         \u001b[39mif\u001b[39;00m gradient_steps \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 369\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain(batch_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_size, gradient_steps\u001b[39m=\u001b[39;49mgradient_steps)\n\u001b[0;32m    371\u001b[0m callback\u001b[39m.\u001b[39mon_training_end()\n\u001b[0;32m    373\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\stable_baselines3\\td3\\td3.py:176\u001b[0m, in \u001b[0;36mTD3.train\u001b[1;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[0;32m    173\u001b[0m     target_q_values \u001b[39m=\u001b[39m replay_data\u001b[39m.\u001b[39mrewards \u001b[39m+\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m replay_data\u001b[39m.\u001b[39mdones) \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgamma \u001b[39m*\u001b[39m next_q_values\n\u001b[0;32m    175\u001b[0m \u001b[39m# Get current Q-values estimates for each critic network\u001b[39;00m\n\u001b[1;32m--> 176\u001b[0m current_q_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcritic(replay_data\u001b[39m.\u001b[39;49mobservations, replay_data\u001b[39m.\u001b[39;49mactions)\n\u001b[0;32m    178\u001b[0m \u001b[39m# Compute critic loss\u001b[39;00m\n\u001b[0;32m    179\u001b[0m critic_loss \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(F\u001b[39m.\u001b[39mmse_loss(current_q, target_q_values) \u001b[39mfor\u001b[39;00m current_q \u001b[39min\u001b[39;00m current_q_values)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\stable_baselines3\\common\\policies.py:885\u001b[0m, in \u001b[0;36mContinuousCritic.forward\u001b[1;34m(self, obs, actions)\u001b[0m\n\u001b[0;32m    883\u001b[0m     features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextract_features(obs)\n\u001b[0;32m    884\u001b[0m qvalue_input \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39mcat([features, actions], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m--> 885\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39;49m(q_net(qvalue_input) \u001b[39mfor\u001b[39;49;00m q_net \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mq_networks)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\stable_baselines3\\common\\policies.py:885\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    883\u001b[0m     features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextract_features(obs)\n\u001b[0;32m    884\u001b[0m qvalue_input \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39mcat([features, actions], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m--> 885\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(q_net(qvalue_input) \u001b[39mfor\u001b[39;00m q_net \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq_networks)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=int(3e5), callback=eval_callback)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
