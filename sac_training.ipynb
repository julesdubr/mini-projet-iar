{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import EvalCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env = make_vec_env(\"LunarLanderContinuous-v2\", n_envs=16)\n",
    "eval_env = gym.make(\"LunarLanderContinuous-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "model = SAC(\n",
    "    \"MlpPolicy\",\n",
    "    train_env,\n",
    "    learning_rate=7.3e-4,\n",
    "    buffer_size=1000000,\n",
    "    batch_size=256,\n",
    "    ent_coef='auto',\n",
    "    gamma=0.99,\n",
    "    tau=0.01,\n",
    "    train_freq=1,\n",
    "    gradient_steps=1,\n",
    "    learning_starts=10000,\n",
    "    policy_kwargs=dict(net_arch=[400, 300]),\n",
    "    verbose=1,\n",
    "    tensorboard_log=\"./runs/sac_lunarcontinuous_tensorboard/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_callback = EvalCallback(\n",
    "    eval_env,\n",
    "    best_model_save_path=\"./logs/continuous/sac\",\n",
    "    log_path=\"./logs/continuous/sac\",\n",
    "    eval_freq=1000,\n",
    "    n_eval_episodes=10,\n",
    "    deterministic=True,\n",
    "    render=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./runs/sac_lunar_tensorboard/SAC_1\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 90.2     |\n",
      "|    ep_rew_mean     | -226     |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 3684     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 1520     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 96.1     |\n",
      "|    ep_rew_mean     | -272     |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 3692     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 1680     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | -263     |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 3771     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 1984     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 106      |\n",
      "|    ep_rew_mean     | -223     |\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 3831     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2576     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 106      |\n",
      "|    ep_rew_mean     | -214     |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 3631     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2832     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 103      |\n",
      "|    ep_rew_mean     | -213     |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 3612     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 3280     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 104      |\n",
      "|    ep_rew_mean     | -206     |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 3492     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 4048     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 105      |\n",
      "|    ep_rew_mean     | -214     |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 3469     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 4288     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 104      |\n",
      "|    ep_rew_mean     | -210     |\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 3428     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 4480     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 103      |\n",
      "|    ep_rew_mean     | -200     |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 3412     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 5184     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 103      |\n",
      "|    ep_rew_mean     | -202     |\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 3300     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 5696     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 103      |\n",
      "|    ep_rew_mean     | -202     |\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 3300     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 5808     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 103      |\n",
      "|    ep_rew_mean     | -206     |\n",
      "| time/              |          |\n",
      "|    episodes        | 52       |\n",
      "|    fps             | 3300     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 6016     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | -202     |\n",
      "| time/              |          |\n",
      "|    episodes        | 56       |\n",
      "|    fps             | 3179     |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 6880     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 101      |\n",
      "|    ep_rew_mean     | -199     |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 3147     |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 7232     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 101      |\n",
      "|    ep_rew_mean     | -204     |\n",
      "| time/              |          |\n",
      "|    episodes        | 64       |\n",
      "|    fps             | 3122     |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 7632     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | -213     |\n",
      "| time/              |          |\n",
      "|    episodes        | 68       |\n",
      "|    fps             | 3095     |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 7952     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=8000, episode_reward=-137.42 +/- 19.66\n",
      "Episode length: 70.40 +/- 14.11\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 70.4     |\n",
      "|    mean_reward     | -137     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 8000     |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | -211     |\n",
      "| time/              |          |\n",
      "|    episodes        | 72       |\n",
      "|    fps             | 2554     |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 8752     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | -210     |\n",
      "| time/              |          |\n",
      "|    episodes        | 76       |\n",
      "|    fps             | 2506     |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 9040     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | -214     |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 2465     |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 9392     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 103      |\n",
      "|    ep_rew_mean     | -208     |\n",
      "| time/              |          |\n",
      "|    episodes        | 84       |\n",
      "|    fps             | 2416     |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 9808     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 103      |\n",
      "|    ep_rew_mean     | -212     |\n",
      "| time/              |          |\n",
      "|    episodes        | 88       |\n",
      "|    fps             | 2089     |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 10464    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.499   |\n",
      "|    critic_loss     | 237      |\n",
      "|    ent_coef        | 0.98     |\n",
      "|    ent_coef_loss   | -0.065   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 28       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 103      |\n",
      "|    ep_rew_mean     | -214     |\n",
      "| time/              |          |\n",
      "|    episodes        | 92       |\n",
      "|    fps             | 1805     |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 11008    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.24     |\n",
      "|    critic_loss     | 241      |\n",
      "|    ent_coef        | 0.957    |\n",
      "|    ent_coef_loss   | -0.144   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 62       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 103      |\n",
      "|    ep_rew_mean     | -215     |\n",
      "| time/              |          |\n",
      "|    episodes        | 96       |\n",
      "|    fps             | 1690     |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 11280    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0676   |\n",
      "|    critic_loss     | 73.8     |\n",
      "|    ent_coef        | 0.945    |\n",
      "|    ent_coef_loss   | -0.18    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 79       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 104      |\n",
      "|    ep_rew_mean     | -213     |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 1529     |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 11744    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.271    |\n",
      "|    critic_loss     | 127      |\n",
      "|    ent_coef        | 0.926    |\n",
      "|    ent_coef_loss   | -0.247   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 108      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 105      |\n",
      "|    ep_rew_mean     | -207     |\n",
      "| time/              |          |\n",
      "|    episodes        | 104      |\n",
      "|    fps             | 1413     |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 12352    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.131    |\n",
      "|    critic_loss     | 99.3     |\n",
      "|    ent_coef        | 0.901    |\n",
      "|    ent_coef_loss   | -0.325   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 146      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 106      |\n",
      "|    ep_rew_mean     | -200     |\n",
      "| time/              |          |\n",
      "|    episodes        | 108      |\n",
      "|    fps             | 1303     |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 13040    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.514    |\n",
      "|    critic_loss     | 79.4     |\n",
      "|    ent_coef        | 0.874    |\n",
      "|    ent_coef_loss   | -0.417   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 189      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 106      |\n",
      "|    ep_rew_mean     | -192     |\n",
      "| time/              |          |\n",
      "|    episodes        | 112      |\n",
      "|    fps             | 1259     |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 13392    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.422    |\n",
      "|    critic_loss     | 107      |\n",
      "|    ent_coef        | 0.861    |\n",
      "|    ent_coef_loss   | -0.448   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 211      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 107      |\n",
      "|    ep_rew_mean     | -195     |\n",
      "| time/              |          |\n",
      "|    episodes        | 116      |\n",
      "|    fps             | 1202     |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 14080    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.21     |\n",
      "|    critic_loss     | 25       |\n",
      "|    ent_coef        | 0.836    |\n",
      "|    ent_coef_loss   | -0.518   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 254      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 108      |\n",
      "|    ep_rew_mean     | -193     |\n",
      "| time/              |          |\n",
      "|    episodes        | 120      |\n",
      "|    fps             | 1142     |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 14880    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.613    |\n",
      "|    critic_loss     | 47.8     |\n",
      "|    ent_coef        | 0.808    |\n",
      "|    ent_coef_loss   | -0.619   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 304      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 110      |\n",
      "|    ep_rew_mean     | -195     |\n",
      "| time/              |          |\n",
      "|    episodes        | 124      |\n",
      "|    fps             | 1100     |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 15552    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.25     |\n",
      "|    critic_loss     | 42.2     |\n",
      "|    ent_coef        | 0.785    |\n",
      "|    ent_coef_loss   | -0.692   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 346      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 111      |\n",
      "|    ep_rew_mean     | -203     |\n",
      "| time/              |          |\n",
      "|    episodes        | 128      |\n",
      "|    fps             | 1092     |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 15648    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.965    |\n",
      "|    critic_loss     | 23.6     |\n",
      "|    ent_coef        | 0.782    |\n",
      "|    ent_coef_loss   | -0.661   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 352      |\n",
      "---------------------------------\n",
      "Eval num_timesteps=16000, episode_reward=-147.86 +/- 94.98\n",
      "Episode length: 140.40 +/- 60.08\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 140      |\n",
      "|    mean_reward     | -148     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 16000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.546    |\n",
      "|    critic_loss     | 52.9     |\n",
      "|    ent_coef        | 0.771    |\n",
      "|    ent_coef_loss   | -0.752   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 374      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 112      |\n",
      "|    ep_rew_mean     | -197     |\n",
      "| time/              |          |\n",
      "|    episodes        | 132      |\n",
      "|    fps             | 948      |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 16944    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.44     |\n",
      "|    critic_loss     | 51.5     |\n",
      "|    ent_coef        | 0.741    |\n",
      "|    ent_coef_loss   | -0.782   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 433      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 124      |\n",
      "|    ep_rew_mean     | -195     |\n",
      "| time/              |          |\n",
      "|    episodes        | 136      |\n",
      "|    fps             | 921      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 17472    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.76     |\n",
      "|    critic_loss     | 17       |\n",
      "|    ent_coef        | 0.726    |\n",
      "|    ent_coef_loss   | -0.882   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 466      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 125      |\n",
      "|    ep_rew_mean     | -199     |\n",
      "| time/              |          |\n",
      "|    episodes        | 140      |\n",
      "|    fps             | 915      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 17696    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.42     |\n",
      "|    critic_loss     | 41.9     |\n",
      "|    ent_coef        | 0.719    |\n",
      "|    ent_coef_loss   | -0.859   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 480      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 127      |\n",
      "|    ep_rew_mean     | -198     |\n",
      "| time/              |          |\n",
      "|    episodes        | 144      |\n",
      "|    fps             | 892      |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 18736    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.52     |\n",
      "|    critic_loss     | 5.28     |\n",
      "|    ent_coef        | 0.689    |\n",
      "|    ent_coef_loss   | -0.903   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 545      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 131      |\n",
      "|    ep_rew_mean     | -197     |\n",
      "| time/              |          |\n",
      "|    episodes        | 148      |\n",
      "|    fps             | 883      |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 19280    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.12     |\n",
      "|    critic_loss     | 26.2     |\n",
      "|    ent_coef        | 0.674    |\n",
      "|    ent_coef_loss   | -0.929   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 579      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 134      |\n",
      "|    ep_rew_mean     | -189     |\n",
      "| time/              |          |\n",
      "|    episodes        | 152      |\n",
      "|    fps             | 870      |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 20512    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.455    |\n",
      "|    critic_loss     | 11.3     |\n",
      "|    ent_coef        | 0.641    |\n",
      "|    ent_coef_loss   | -1.08    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 656      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 137      |\n",
      "|    ep_rew_mean     | -185     |\n",
      "| time/              |          |\n",
      "|    episodes        | 156      |\n",
      "|    fps             | 862      |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 21168    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.134    |\n",
      "|    critic_loss     | 17       |\n",
      "|    ent_coef        | 0.624    |\n",
      "|    ent_coef_loss   | -1.24    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 697      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 142      |\n",
      "|    ep_rew_mean     | -186     |\n",
      "| time/              |          |\n",
      "|    episodes        | 160      |\n",
      "|    fps             | 846      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 22096    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.53     |\n",
      "|    critic_loss     | 17.9     |\n",
      "|    ent_coef        | 0.601    |\n",
      "|    ent_coef_loss   | -1.33    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 755      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 149      |\n",
      "|    ep_rew_mean     | -180     |\n",
      "| time/              |          |\n",
      "|    episodes        | 164      |\n",
      "|    fps             | 820      |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 23296    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.1      |\n",
      "|    critic_loss     | 102      |\n",
      "|    ent_coef        | 0.572    |\n",
      "|    ent_coef_loss   | -1.42    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 830      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 152      |\n",
      "|    ep_rew_mean     | -171     |\n",
      "| time/              |          |\n",
      "|    episodes        | 168      |\n",
      "|    fps             | 811      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 23888    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.764    |\n",
      "|    critic_loss     | 9.75     |\n",
      "|    ent_coef        | 0.558    |\n",
      "|    ent_coef_loss   | -1.39    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 867      |\n",
      "---------------------------------\n",
      "Eval num_timesteps=24000, episode_reward=-163.72 +/- 75.67\n",
      "Episode length: 540.00 +/- 132.39\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 540      |\n",
      "|    mean_reward     | -164     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 24000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.7      |\n",
      "|    critic_loss     | 16.5     |\n",
      "|    ent_coef        | 0.556    |\n",
      "|    ent_coef_loss   | -1.42    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 874      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 156      |\n",
      "|    ep_rew_mean     | -171     |\n",
      "| time/              |          |\n",
      "|    episodes        | 172      |\n",
      "|    fps             | 671      |\n",
      "|    time_elapsed    | 37       |\n",
      "|    total_timesteps | 24976    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.51     |\n",
      "|    critic_loss     | 27       |\n",
      "|    ent_coef        | 0.534    |\n",
      "|    ent_coef_loss   | -1.5     |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 935      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 164      |\n",
      "|    ep_rew_mean     | -166     |\n",
      "| time/              |          |\n",
      "|    episodes        | 176      |\n",
      "|    fps             | 663      |\n",
      "|    time_elapsed    | 38       |\n",
      "|    total_timesteps | 25856    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.67     |\n",
      "|    critic_loss     | 18.9     |\n",
      "|    ent_coef        | 0.515    |\n",
      "|    ent_coef_loss   | -1.66    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 990      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 169      |\n",
      "|    ep_rew_mean     | -159     |\n",
      "| time/              |          |\n",
      "|    episodes        | 180      |\n",
      "|    fps             | 645      |\n",
      "|    time_elapsed    | 42       |\n",
      "|    total_timesteps | 27424    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.79     |\n",
      "|    critic_loss     | 11.7     |\n",
      "|    ent_coef        | 0.484    |\n",
      "|    ent_coef_loss   | -1.55    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 1088     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 175      |\n",
      "|    ep_rew_mean     | -159     |\n",
      "| time/              |          |\n",
      "|    episodes        | 184      |\n",
      "|    fps             | 639      |\n",
      "|    time_elapsed    | 46       |\n",
      "|    total_timesteps | 29680    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.193   |\n",
      "|    critic_loss     | 13.7     |\n",
      "|    ent_coef        | 0.443    |\n",
      "|    ent_coef_loss   | -1.83    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 1229     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=32000, episode_reward=-165.65 +/- 14.40\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -166     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 32000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.81     |\n",
      "|    critic_loss     | 21.6     |\n",
      "|    ent_coef        | 0.405    |\n",
      "|    ent_coef_loss   | -1.61    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 1374     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 198      |\n",
      "|    ep_rew_mean     | -153     |\n",
      "| time/              |          |\n",
      "|    episodes        | 188      |\n",
      "|    fps             | 431      |\n",
      "|    time_elapsed    | 90       |\n",
      "|    total_timesteps | 39200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.931    |\n",
      "|    critic_loss     | 24.9     |\n",
      "|    ent_coef        | 0.309    |\n",
      "|    ent_coef_loss   | -2.19    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 1824     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-62.79 +/- 27.11\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -62.8    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 40000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.482    |\n",
      "|    critic_loss     | 25.8     |\n",
      "|    ent_coef        | 0.299    |\n",
      "|    ent_coef_loss   | -2.3     |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 1874     |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 234      |\n",
      "|    ep_rew_mean     | -143     |\n",
      "| time/              |          |\n",
      "|    episodes        | 192      |\n",
      "|    fps             | 354      |\n",
      "|    time_elapsed    | 118      |\n",
      "|    total_timesteps | 41856    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.0896  |\n",
      "|    critic_loss     | 15.2     |\n",
      "|    ent_coef        | 0.28     |\n",
      "|    ent_coef_loss   | -2.03    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 1990     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 270      |\n",
      "|    ep_rew_mean     | -136     |\n",
      "| time/              |          |\n",
      "|    episodes        | 196      |\n",
      "|    fps             | 349      |\n",
      "|    time_elapsed    | 124      |\n",
      "|    total_timesteps | 43424    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.89    |\n",
      "|    critic_loss     | 10.5     |\n",
      "|    ent_coef        | 0.264    |\n",
      "|    ent_coef_loss   | -2.22    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 2088     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 305      |\n",
      "|    ep_rew_mean     | -130     |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 348      |\n",
      "|    time_elapsed    | 130      |\n",
      "|    total_timesteps | 45680    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.54    |\n",
      "|    critic_loss     | 11.5     |\n",
      "|    ent_coef        | 0.244    |\n",
      "|    ent_coef_loss   | -2.31    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 2229     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=48000, episode_reward=-64.68 +/- 23.42\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -64.7    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 48000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.11    |\n",
      "|    critic_loss     | 11.7     |\n",
      "|    ent_coef        | 0.225    |\n",
      "|    ent_coef_loss   | -2.24    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 2374     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 341      |\n",
      "|    ep_rew_mean     | -129     |\n",
      "| time/              |          |\n",
      "|    episodes        | 204      |\n",
      "|    fps             | 308      |\n",
      "|    time_elapsed    | 179      |\n",
      "|    total_timesteps | 55200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.12    |\n",
      "|    critic_loss     | 9.48     |\n",
      "|    ent_coef        | 0.174    |\n",
      "|    ent_coef_loss   | -2.88    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 2824     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=56000, episode_reward=-53.56 +/- 14.84\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -53.6    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 56000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.74    |\n",
      "|    critic_loss     | 10.9     |\n",
      "|    ent_coef        | 0.169    |\n",
      "|    ent_coef_loss   | -2.58    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 2874     |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 376      |\n",
      "|    ep_rew_mean     | -124     |\n",
      "| time/              |          |\n",
      "|    episodes        | 208      |\n",
      "|    fps             | 281      |\n",
      "|    time_elapsed    | 205      |\n",
      "|    total_timesteps | 57856    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.57    |\n",
      "|    critic_loss     | 18.7     |\n",
      "|    ent_coef        | 0.158    |\n",
      "|    ent_coef_loss   | -2.2     |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 2990     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 410      |\n",
      "|    ep_rew_mean     | -125     |\n",
      "| time/              |          |\n",
      "|    episodes        | 212      |\n",
      "|    fps             | 280      |\n",
      "|    time_elapsed    | 211      |\n",
      "|    total_timesteps | 59424    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.04    |\n",
      "|    critic_loss     | 17.8     |\n",
      "|    ent_coef        | 0.15     |\n",
      "|    ent_coef_loss   | -2.87    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 3088     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 446      |\n",
      "|    ep_rew_mean     | -121     |\n",
      "| time/              |          |\n",
      "|    episodes        | 216      |\n",
      "|    fps             | 283      |\n",
      "|    time_elapsed    | 217      |\n",
      "|    total_timesteps | 61680    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.05    |\n",
      "|    critic_loss     | 9.41     |\n",
      "|    ent_coef        | 0.138    |\n",
      "|    ent_coef_loss   | -2.44    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 3229     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=64000, episode_reward=-38.75 +/- 30.44\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -38.7    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 64000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.5     |\n",
      "|    critic_loss     | 38.2     |\n",
      "|    ent_coef        | 0.128    |\n",
      "|    ent_coef_loss   | -2.66    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 3374     |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 480      |\n",
      "|    ep_rew_mean     | -116     |\n",
      "| time/              |          |\n",
      "|    episodes        | 220      |\n",
      "|    fps             | 273      |\n",
      "|    time_elapsed    | 260      |\n",
      "|    total_timesteps | 71200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.76    |\n",
      "|    critic_loss     | 7.88     |\n",
      "|    ent_coef        | 0.1      |\n",
      "|    ent_coef_loss   | -2.37    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 3824     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=72000, episode_reward=-66.25 +/- 66.38\n",
      "Episode length: 984.20 +/- 31.60\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 984      |\n",
      "|    mean_reward     | -66.3    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 72000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.67    |\n",
      "|    critic_loss     | 4.53     |\n",
      "|    ent_coef        | 0.0977   |\n",
      "|    ent_coef_loss   | -2.25    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 3874     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 514      |\n",
      "|    ep_rew_mean     | -109     |\n",
      "| time/              |          |\n",
      "|    episodes        | 224      |\n",
      "|    fps             | 262      |\n",
      "|    time_elapsed    | 281      |\n",
      "|    total_timesteps | 73856    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.6     |\n",
      "|    critic_loss     | 22.1     |\n",
      "|    ent_coef        | 0.0916   |\n",
      "|    ent_coef_loss   | -2.32    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 3990     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 549      |\n",
      "|    ep_rew_mean     | -99      |\n",
      "| time/              |          |\n",
      "|    episodes        | 228      |\n",
      "|    fps             | 264      |\n",
      "|    time_elapsed    | 285      |\n",
      "|    total_timesteps | 75424    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.17    |\n",
      "|    critic_loss     | 50.4     |\n",
      "|    ent_coef        | 0.0868   |\n",
      "|    ent_coef_loss   | -2.18    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 4088     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 583      |\n",
      "|    ep_rew_mean     | -92.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 232      |\n",
      "|    fps             | 266      |\n",
      "|    time_elapsed    | 291      |\n",
      "|    total_timesteps | 77680    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.48    |\n",
      "|    critic_loss     | 8.34     |\n",
      "|    ent_coef        | 0.0807   |\n",
      "|    ent_coef_loss   | -2.08    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 4229     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-62.27 +/- 35.09\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -62.3    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 80000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.14    |\n",
      "|    critic_loss     | 6.62     |\n",
      "|    ent_coef        | 0.075    |\n",
      "|    ent_coef_loss   | -1.81    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 4374     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 607      |\n",
      "|    ep_rew_mean     | -89.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 236      |\n",
      "|    fps             | 262      |\n",
      "|    time_elapsed    | 332      |\n",
      "|    total_timesteps | 87200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.13    |\n",
      "|    critic_loss     | 2.04     |\n",
      "|    ent_coef        | 0.0604   |\n",
      "|    ent_coef_loss   | -2.38    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 4824     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=88000, episode_reward=-97.39 +/- 86.26\n",
      "Episode length: 907.20 +/- 119.24\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 907      |\n",
      "|    mean_reward     | -97.4    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 88000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.1    |\n",
      "|    critic_loss     | 2.13     |\n",
      "|    ent_coef        | 0.0589   |\n",
      "|    ent_coef_loss   | -3.39    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 4874     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 642      |\n",
      "|    ep_rew_mean     | -85.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 240      |\n",
      "|    fps             | 255      |\n",
      "|    time_elapsed    | 351      |\n",
      "|    total_timesteps | 89856    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -10.1    |\n",
      "|    critic_loss     | 5.91     |\n",
      "|    ent_coef        | 0.0558   |\n",
      "|    ent_coef_loss   | -1.21    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 4990     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 676      |\n",
      "|    ep_rew_mean     | -82.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 244      |\n",
      "|    fps             | 256      |\n",
      "|    time_elapsed    | 356      |\n",
      "|    total_timesteps | 91424    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.8    |\n",
      "|    critic_loss     | 3.42     |\n",
      "|    ent_coef        | 0.0533   |\n",
      "|    ent_coef_loss   | -1.37    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 5088     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 708      |\n",
      "|    ep_rew_mean     | -77.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 248      |\n",
      "|    fps             | 259      |\n",
      "|    time_elapsed    | 361      |\n",
      "|    total_timesteps | 93680    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.2    |\n",
      "|    critic_loss     | 1.84     |\n",
      "|    ent_coef        | 0.0499   |\n",
      "|    ent_coef_loss   | -3.03    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 5229     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=96000, episode_reward=-29.77 +/- 15.09\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -29.8    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 96000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -10.5    |\n",
      "|    critic_loss     | 10.7     |\n",
      "|    ent_coef        | 0.0469   |\n",
      "|    ent_coef_loss   | -1.74    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 5374     |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 742      |\n",
      "|    ep_rew_mean     | -75.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 252      |\n",
      "|    fps             | 254      |\n",
      "|    time_elapsed    | 404      |\n",
      "|    total_timesteps | 103200   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.78    |\n",
      "|    critic_loss     | 15       |\n",
      "|    ent_coef        | 0.0386   |\n",
      "|    ent_coef_loss   | -2.24    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 5824     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=104000, episode_reward=-33.52 +/- 17.37\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -33.5    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 104000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.03    |\n",
      "|    critic_loss     | 2.41     |\n",
      "|    ent_coef        | 0.0377   |\n",
      "|    ent_coef_loss   | -1.56    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 5874     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 775      |\n",
      "|    ep_rew_mean     | -74.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 256      |\n",
      "|    fps             | 247      |\n",
      "|    time_elapsed    | 428      |\n",
      "|    total_timesteps | 105856   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.46    |\n",
      "|    critic_loss     | 18.2     |\n",
      "|    ent_coef        | 0.0354   |\n",
      "|    ent_coef_loss   | -2.98    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 5990     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 806      |\n",
      "|    ep_rew_mean     | -68.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 260      |\n",
      "|    fps             | 248      |\n",
      "|    time_elapsed    | 432      |\n",
      "|    total_timesteps | 107424   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -10.8    |\n",
      "|    critic_loss     | 16.5     |\n",
      "|    ent_coef        | 0.0336   |\n",
      "|    ent_coef_loss   | -1.44    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 6088     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 836      |\n",
      "|    ep_rew_mean     | -64.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 264      |\n",
      "|    fps             | 249      |\n",
      "|    time_elapsed    | 439      |\n",
      "|    total_timesteps | 109680   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -10.2    |\n",
      "|    critic_loss     | 6.81     |\n",
      "|    ent_coef        | 0.0321   |\n",
      "|    ent_coef_loss   | -0.541   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 6229     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=112000, episode_reward=-13.86 +/- 13.55\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -13.9    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 112000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.46    |\n",
      "|    critic_loss     | 3.68     |\n",
      "|    ent_coef        | 0.0308   |\n",
      "|    ent_coef_loss   | 1.18     |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 6374     |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 868      |\n",
      "|    ep_rew_mean     | -61      |\n",
      "| time/              |          |\n",
      "|    episodes        | 268      |\n",
      "|    fps             | 247      |\n",
      "|    time_elapsed    | 480      |\n",
      "|    total_timesteps | 119200   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.5    |\n",
      "|    critic_loss     | 1.29     |\n",
      "|    ent_coef        | 0.0277   |\n",
      "|    ent_coef_loss   | -0.633   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 6824     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=-21.06 +/- 9.25\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -21.1    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 120000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.62    |\n",
      "|    critic_loss     | 12.8     |\n",
      "|    ent_coef        | 0.0278   |\n",
      "|    ent_coef_loss   | 0.0544   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 6874     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 899      |\n",
      "|    ep_rew_mean     | -54.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 272      |\n",
      "|    fps             | 240      |\n",
      "|    time_elapsed    | 506      |\n",
      "|    total_timesteps | 121856   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.15    |\n",
      "|    critic_loss     | 2.67     |\n",
      "|    ent_coef        | 0.0281   |\n",
      "|    ent_coef_loss   | 2.31     |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 6990     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 928      |\n",
      "|    ep_rew_mean     | -53.1    |\n",
      "| time/              |          |\n",
      "|    episodes        | 276      |\n",
      "|    fps             | 241      |\n",
      "|    time_elapsed    | 512      |\n",
      "|    total_timesteps | 123424   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.42    |\n",
      "|    critic_loss     | 16       |\n",
      "|    ent_coef        | 0.0288   |\n",
      "|    ent_coef_loss   | -0.334   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 7088     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 958      |\n",
      "|    ep_rew_mean     | -49.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 280      |\n",
      "|    fps             | 242      |\n",
      "|    time_elapsed    | 518      |\n",
      "|    total_timesteps | 125680   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -10      |\n",
      "|    critic_loss     | 3.09     |\n",
      "|    ent_coef        | 0.0301   |\n",
      "|    ent_coef_loss   | 1.83     |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 7229     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=128000, episode_reward=-13.01 +/- 11.99\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -13      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 128000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.24    |\n",
      "|    critic_loss     | 13.4     |\n",
      "|    ent_coef        | 0.0313   |\n",
      "|    ent_coef_loss   | 0.596    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 7374     |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 988      |\n",
      "|    ep_rew_mean     | -46.7    |\n",
      "| time/              |          |\n",
      "|    episodes        | 284      |\n",
      "|    fps             | 238      |\n",
      "|    time_elapsed    | 567      |\n",
      "|    total_timesteps | 135200   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.32    |\n",
      "|    critic_loss     | 13.1     |\n",
      "|    ent_coef        | 0.0327   |\n",
      "|    ent_coef_loss   | -0.723   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 7824     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=136000, episode_reward=-44.48 +/- 88.95\n",
      "Episode length: 833.00 +/- 334.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 833      |\n",
      "|    mean_reward     | -44.5    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 136000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -10.4    |\n",
      "|    critic_loss     | 6.67     |\n",
      "|    ent_coef        | 0.0329   |\n",
      "|    ent_coef_loss   | 2.74     |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 7874     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -43      |\n",
      "| time/              |          |\n",
      "|    episodes        | 288      |\n",
      "|    fps             | 234      |\n",
      "|    time_elapsed    | 589      |\n",
      "|    total_timesteps | 137856   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.1    |\n",
      "|    critic_loss     | 4.92     |\n",
      "|    ent_coef        | 0.0342   |\n",
      "|    ent_coef_loss   | 0.525    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 7990     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -42      |\n",
      "| time/              |          |\n",
      "|    episodes        | 292      |\n",
      "|    fps             | 234      |\n",
      "|    time_elapsed    | 595      |\n",
      "|    total_timesteps | 139424   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -10.4    |\n",
      "|    critic_loss     | 2.46     |\n",
      "|    ent_coef        | 0.0334   |\n",
      "|    ent_coef_loss   | -1.33    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 8088     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -40.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 296      |\n",
      "|    fps             | 235      |\n",
      "|    time_elapsed    | 601      |\n",
      "|    total_timesteps | 141680   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.4    |\n",
      "|    critic_loss     | 1.28     |\n",
      "|    ent_coef        | 0.0326   |\n",
      "|    ent_coef_loss   | -0.356   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 8229     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=144000, episode_reward=37.08 +/- 64.35\n",
      "Episode length: 832.80 +/- 329.92\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 833      |\n",
      "|    mean_reward     | 37.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 144000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -13      |\n",
      "|    critic_loss     | 5.27     |\n",
      "|    ent_coef        | 0.0319   |\n",
      "|    ent_coef_loss   | 0.0582   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 8374     |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 985      |\n",
      "|    ep_rew_mean     | -36.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 300      |\n",
      "|    fps             | 233      |\n",
      "|    time_elapsed    | 635      |\n",
      "|    total_timesteps | 148480   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.6    |\n",
      "|    critic_loss     | 1.99     |\n",
      "|    ent_coef        | 0.034    |\n",
      "|    ent_coef_loss   | 1.72     |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 8654     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 975      |\n",
      "|    ep_rew_mean     | -32.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 304      |\n",
      "|    fps             | 234      |\n",
      "|    time_elapsed    | 644      |\n",
      "|    total_timesteps | 151200   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -13      |\n",
      "|    critic_loss     | 2.12     |\n",
      "|    ent_coef        | 0.0363   |\n",
      "|    ent_coef_loss   | 0.264    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 8824     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=152000, episode_reward=59.23 +/- 122.77\n",
      "Episode length: 844.80 +/- 310.40\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 845      |\n",
      "|    mean_reward     | 59.2     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 152000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -10.2    |\n",
      "|    critic_loss     | 6.6      |\n",
      "|    ent_coef        | 0.0372   |\n",
      "|    ent_coef_loss   | 0.377    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 8874     |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 975      |\n",
      "|    ep_rew_mean     | -32      |\n",
      "| time/              |          |\n",
      "|    episodes        | 308      |\n",
      "|    fps             | 230      |\n",
      "|    time_elapsed    | 668      |\n",
      "|    total_timesteps | 154336   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.2    |\n",
      "|    critic_loss     | 3.35     |\n",
      "|    ent_coef        | 0.0388   |\n",
      "|    ent_coef_loss   | -0.239   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 9020     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 975      |\n",
      "|    ep_rew_mean     | -30.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 312      |\n",
      "|    fps             | 231      |\n",
      "|    time_elapsed    | 672      |\n",
      "|    total_timesteps | 155744   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.7    |\n",
      "|    critic_loss     | 7.76     |\n",
      "|    ent_coef        | 0.0386   |\n",
      "|    ent_coef_loss   | 1.01     |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 9108     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 967      |\n",
      "|    ep_rew_mean     | -28.1    |\n",
      "| time/              |          |\n",
      "|    episodes        | 316      |\n",
      "|    fps             | 232      |\n",
      "|    time_elapsed    | 678      |\n",
      "|    total_timesteps | 157936   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.2    |\n",
      "|    critic_loss     | 3.26     |\n",
      "|    ent_coef        | 0.0391   |\n",
      "|    ent_coef_loss   | 0.355    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 9245     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=-9.43 +/- 22.44\n",
      "Episode length: 829.00 +/- 342.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 829      |\n",
      "|    mean_reward     | -9.43    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 160000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.1    |\n",
      "|    critic_loss     | 6.09     |\n",
      "|    ent_coef        | 0.0397   |\n",
      "|    ent_coef_loss   | -0.0943  |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 9374     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 967      |\n",
      "|    ep_rew_mean     | -26.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 320      |\n",
      "|    fps             | 231      |\n",
      "|    time_elapsed    | 718      |\n",
      "|    total_timesteps | 166160   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -13.4    |\n",
      "|    critic_loss     | 6.16     |\n",
      "|    ent_coef        | 0.0386   |\n",
      "|    ent_coef_loss   | 0.238    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 9759     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=168000, episode_reward=-39.57 +/- 16.47\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -39.6    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 168000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -13.3    |\n",
      "|    critic_loss     | 2.01     |\n",
      "|    ent_coef        | 0.0405   |\n",
      "|    ent_coef_loss   | 1.17     |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 9874     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 959      |\n",
      "|    ep_rew_mean     | -24.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 324      |\n",
      "|    fps             | 227      |\n",
      "|    time_elapsed    | 742      |\n",
      "|    total_timesteps | 168976   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.1    |\n",
      "|    critic_loss     | 4.43     |\n",
      "|    ent_coef        | 0.0414   |\n",
      "|    ent_coef_loss   | 0.464    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 9935     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 959      |\n",
      "|    ep_rew_mean     | -22      |\n",
      "| time/              |          |\n",
      "|    episodes        | 328      |\n",
      "|    fps             | 228      |\n",
      "|    time_elapsed    | 750      |\n",
      "|    total_timesteps | 171408   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -13.7    |\n",
      "|    critic_loss     | 2.22     |\n",
      "|    ent_coef        | 0.0399   |\n",
      "|    ent_coef_loss   | -0.494   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 10087    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 959      |\n",
      "|    ep_rew_mean     | -21.7    |\n",
      "| time/              |          |\n",
      "|    episodes        | 332      |\n",
      "|    fps             | 229      |\n",
      "|    time_elapsed    | 756      |\n",
      "|    total_timesteps | 173680   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -13.8    |\n",
      "|    critic_loss     | 8.25     |\n",
      "|    ent_coef        | 0.0383   |\n",
      "|    ent_coef_loss   | -1.19    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 10229    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=176000, episode_reward=9.54 +/- 42.55\n",
      "Episode length: 669.80 +/- 404.41\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 670      |\n",
      "|    mean_reward     | 9.54     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 176000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.8    |\n",
      "|    critic_loss     | 2.92     |\n",
      "|    ent_coef        | 0.0372   |\n",
      "|    ent_coef_loss   | 0.0425   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 10374    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 936      |\n",
      "|    ep_rew_mean     | -17.1    |\n",
      "| time/              |          |\n",
      "|    episodes        | 336      |\n",
      "|    fps             | 228      |\n",
      "|    time_elapsed    | 776      |\n",
      "|    total_timesteps | 177616   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.7    |\n",
      "|    critic_loss     | 1.53     |\n",
      "|    ent_coef        | 0.0384   |\n",
      "|    ent_coef_loss   | -0.188   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 10475    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 927      |\n",
      "|    ep_rew_mean     | -13.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 340      |\n",
      "|    fps             | 230      |\n",
      "|    time_elapsed    | 791      |\n",
      "|    total_timesteps | 182160   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.1    |\n",
      "|    critic_loss     | 4.62     |\n",
      "|    ent_coef        | 0.0407   |\n",
      "|    ent_coef_loss   | 0.903    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 10759    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=184000, episode_reward=19.49 +/- 41.33\n",
      "Episode length: 659.60 +/- 416.91\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 660      |\n",
      "|    mean_reward     | 19.5     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 184000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15      |\n",
      "|    critic_loss     | 2.29     |\n",
      "|    ent_coef        | 0.0415   |\n",
      "|    ent_coef_loss   | 1.07     |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 10874    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 919      |\n",
      "|    ep_rew_mean     | -11.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 344      |\n",
      "|    fps             | 228      |\n",
      "|    time_elapsed    | 807      |\n",
      "|    total_timesteps | 184512   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.8    |\n",
      "|    critic_loss     | 2.6      |\n",
      "|    ent_coef        | 0.0417   |\n",
      "|    ent_coef_loss   | 0.95     |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 10906    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 904      |\n",
      "|    ep_rew_mean     | -5.53    |\n",
      "| time/              |          |\n",
      "|    episodes        | 348      |\n",
      "|    fps             | 229      |\n",
      "|    time_elapsed    | 812      |\n",
      "|    total_timesteps | 186160   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.4    |\n",
      "|    critic_loss     | 3.39     |\n",
      "|    ent_coef        | 0.0425   |\n",
      "|    ent_coef_loss   | 2.67     |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 11009    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 895      |\n",
      "|    ep_rew_mean     | -4.81    |\n",
      "| time/              |          |\n",
      "|    episodes        | 352      |\n",
      "|    fps             | 230      |\n",
      "|    time_elapsed    | 817      |\n",
      "|    total_timesteps | 187984   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.6    |\n",
      "|    critic_loss     | 5.41     |\n",
      "|    ent_coef        | 0.0441   |\n",
      "|    ent_coef_loss   | 0.397    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 11123    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 880      |\n",
      "|    ep_rew_mean     | -1.44    |\n",
      "| time/              |          |\n",
      "|    episodes        | 356      |\n",
      "|    fps             | 230      |\n",
      "|    time_elapsed    | 821      |\n",
      "|    total_timesteps | 189696   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.3    |\n",
      "|    critic_loss     | 1.82     |\n",
      "|    ent_coef        | 0.0444   |\n",
      "|    ent_coef_loss   | 0.732    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 11230    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=192000, episode_reward=67.47 +/- 82.57\n",
      "Episode length: 779.60 +/- 326.17\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 780      |\n",
      "|    mean_reward     | 67.5     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 192000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.5    |\n",
      "|    critic_loss     | 2.89     |\n",
      "|    ent_coef        | 0.0454   |\n",
      "|    ent_coef_loss   | -0.366   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 11374    |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 864      |\n",
      "|    ep_rew_mean     | 2.81     |\n",
      "| time/              |          |\n",
      "|    episodes        | 360      |\n",
      "|    fps             | 229      |\n",
      "|    time_elapsed    | 842      |\n",
      "|    total_timesteps | 193616   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.6    |\n",
      "|    critic_loss     | 3.81     |\n",
      "|    ent_coef        | 0.0456   |\n",
      "|    ent_coef_loss   | -0.181   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 11475    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 864      |\n",
      "|    ep_rew_mean     | 3.89     |\n",
      "| time/              |          |\n",
      "|    episodes        | 364      |\n",
      "|    fps             | 231      |\n",
      "|    time_elapsed    | 860      |\n",
      "|    total_timesteps | 199424   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.9    |\n",
      "|    critic_loss     | 4.35     |\n",
      "|    ent_coef        | 0.0398   |\n",
      "|    ent_coef_loss   | -0.251   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 11838    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=44.30 +/- 68.25\n",
      "Episode length: 661.00 +/- 411.13\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 661      |\n",
      "|    mean_reward     | 44.3     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 200000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.6    |\n",
      "|    critic_loss     | 20.1     |\n",
      "|    ent_coef        | 0.0393   |\n",
      "|    ent_coef_loss   | 0.864    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 11874    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 855      |\n",
      "|    ep_rew_mean     | 4.33     |\n",
      "| time/              |          |\n",
      "|    episodes        | 368      |\n",
      "|    fps             | 230      |\n",
      "|    time_elapsed    | 877      |\n",
      "|    total_timesteps | 202160   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.2    |\n",
      "|    critic_loss     | 1.8      |\n",
      "|    ent_coef        | 0.0384   |\n",
      "|    ent_coef_loss   | -0.294   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 12009    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 841      |\n",
      "|    ep_rew_mean     | 10.7     |\n",
      "| time/              |          |\n",
      "|    episodes        | 372      |\n",
      "|    fps             | 231      |\n",
      "|    time_elapsed    | 886      |\n",
      "|    total_timesteps | 205312   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.6    |\n",
      "|    critic_loss     | 3.36     |\n",
      "|    ent_coef        | 0.0386   |\n",
      "|    ent_coef_loss   | -0.086   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 12206    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 841      |\n",
      "|    ep_rew_mean     | 12.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 376      |\n",
      "|    fps             | 232      |\n",
      "|    time_elapsed    | 889      |\n",
      "|    total_timesteps | 206480   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.1    |\n",
      "|    critic_loss     | 3.26     |\n",
      "|    ent_coef        | 0.0388   |\n",
      "|    ent_coef_loss   | -0.89    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 12279    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=208000, episode_reward=82.99 +/- 107.54\n",
      "Episode length: 749.40 +/- 311.98\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 749      |\n",
      "|    mean_reward     | 83       |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 208000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.7    |\n",
      "|    critic_loss     | 1.68     |\n",
      "|    ent_coef        | 0.0392   |\n",
      "|    ent_coef_loss   | -0.115   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 12374    |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 835      |\n",
      "|    ep_rew_mean     | 15       |\n",
      "| time/              |          |\n",
      "|    episodes        | 380      |\n",
      "|    fps             | 231      |\n",
      "|    time_elapsed    | 906      |\n",
      "|    total_timesteps | 209616   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.5    |\n",
      "|    critic_loss     | 3.68     |\n",
      "|    ent_coef        | 0.0385   |\n",
      "|    ent_coef_loss   | -1.49    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 12475    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 831      |\n",
      "|    ep_rew_mean     | 17.7     |\n",
      "| time/              |          |\n",
      "|    episodes        | 384      |\n",
      "|    fps             | 233      |\n",
      "|    time_elapsed    | 923      |\n",
      "|    total_timesteps | 215424   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.5    |\n",
      "|    critic_loss     | 2.3      |\n",
      "|    ent_coef        | 0.0319   |\n",
      "|    ent_coef_loss   | 0.864    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 12838    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=216000, episode_reward=-19.56 +/- 16.34\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -19.6    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 216000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -13.9    |\n",
      "|    critic_loss     | 3.18     |\n",
      "|    ent_coef        | 0.0322   |\n",
      "|    ent_coef_loss   | 0.872    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 12874    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 826      |\n",
      "|    ep_rew_mean     | 20.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 388      |\n",
      "|    fps             | 231      |\n",
      "|    time_elapsed    | 950      |\n",
      "|    total_timesteps | 219744   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.3    |\n",
      "|    critic_loss     | 3.01     |\n",
      "|    ent_coef        | 0.0343   |\n",
      "|    ent_coef_loss   | -0.893   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 13108    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 814      |\n",
      "|    ep_rew_mean     | 26.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 392      |\n",
      "|    fps             | 231      |\n",
      "|    time_elapsed    | 956      |\n",
      "|    total_timesteps | 221472   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.7    |\n",
      "|    critic_loss     | 2.31     |\n",
      "|    ent_coef        | 0.0328   |\n",
      "|    ent_coef_loss   | 1.12     |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 13216    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 809      |\n",
      "|    ep_rew_mean     | 23.7     |\n",
      "| time/              |          |\n",
      "|    episodes        | 396      |\n",
      "|    fps             | 232      |\n",
      "|    time_elapsed    | 958      |\n",
      "|    total_timesteps | 222480   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.6    |\n",
      "|    critic_loss     | 1.84     |\n",
      "|    ent_coef        | 0.0328   |\n",
      "|    ent_coef_loss   | -0.551   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 13279    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=224000, episode_reward=89.80 +/- 122.62\n",
      "Episode length: 871.60 +/- 207.07\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 872      |\n",
      "|    mean_reward     | 89.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 224000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -13.3    |\n",
      "|    critic_loss     | 7.91     |\n",
      "|    ent_coef        | 0.032    |\n",
      "|    ent_coef_loss   | -0.712   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 13374    |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 820      |\n",
      "|    ep_rew_mean     | 22.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 400      |\n",
      "|    fps             | 231      |\n",
      "|    time_elapsed    | 976      |\n",
      "|    total_timesteps | 225680   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.7    |\n",
      "|    critic_loss     | 7.14     |\n",
      "|    ent_coef        | 0.0307   |\n",
      "|    ent_coef_loss   | 0.344    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 13479    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 810      |\n",
      "|    ep_rew_mean     | 27.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 404      |\n",
      "|    fps             | 233      |\n",
      "|    time_elapsed    | 988      |\n",
      "|    total_timesteps | 231200   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -13.1    |\n",
      "|    critic_loss     | 7.72     |\n",
      "|    ent_coef        | 0.0304   |\n",
      "|    ent_coef_loss   | 0.386    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 13824    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=232000, episode_reward=47.66 +/- 105.86\n",
      "Episode length: 846.00 +/- 308.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 846      |\n",
      "|    mean_reward     | 47.7     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 232000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.3    |\n",
      "|    critic_loss     | 7.34     |\n",
      "|    ent_coef        | 0.0302   |\n",
      "|    ent_coef_loss   | 0.335    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 13874    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 810      |\n",
      "|    ep_rew_mean     | 28.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 408      |\n",
      "|    fps             | 233      |\n",
      "|    time_elapsed    | 1015     |\n",
      "|    total_timesteps | 237120   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.7    |\n",
      "|    critic_loss     | 3.31     |\n",
      "|    ent_coef        | 0.03     |\n",
      "|    ent_coef_loss   | 0.0851   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 14194    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 802      |\n",
      "|    ep_rew_mean     | 31       |\n",
      "| time/              |          |\n",
      "|    episodes        | 412      |\n",
      "|    fps             | 233      |\n",
      "|    time_elapsed    | 1019     |\n",
      "|    total_timesteps | 238384   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.2    |\n",
      "|    critic_loss     | 1.29     |\n",
      "|    ent_coef        | 0.0303   |\n",
      "|    ent_coef_loss   | 0.107    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 14273    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=213.08 +/- 108.66\n",
      "Episode length: 447.40 +/- 281.34\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 447      |\n",
      "|    mean_reward     | 213      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 240000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.7    |\n",
      "|    critic_loss     | 33.2     |\n",
      "|    ent_coef        | 0.0297   |\n",
      "|    ent_coef_loss   | -0.694   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 14374    |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 811      |\n",
      "|    ep_rew_mean     | 29.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 416      |\n",
      "|    fps             | 233      |\n",
      "|    time_elapsed    | 1033     |\n",
      "|    total_timesteps | 241616   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.4    |\n",
      "|    critic_loss     | 4.63     |\n",
      "|    ent_coef        | 0.029    |\n",
      "|    ent_coef_loss   | 0.54     |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 14475    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 811      |\n",
      "|    ep_rew_mean     | 29.7     |\n",
      "| time/              |          |\n",
      "|    episodes        | 420      |\n",
      "|    fps             | 234      |\n",
      "|    time_elapsed    | 1036     |\n",
      "|    total_timesteps | 242976   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.9    |\n",
      "|    critic_loss     | 1.52     |\n",
      "|    ent_coef        | 0.0283   |\n",
      "|    ent_coef_loss   | 0.285    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 14560    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=248000, episode_reward=-9.45 +/- 12.21\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -9.45    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 248000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -13.2    |\n",
      "|    critic_loss     | 1.72     |\n",
      "|    ent_coef        | 0.0307   |\n",
      "|    ent_coef_loss   | 1.17     |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 14874    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 819      |\n",
      "|    ep_rew_mean     | 29.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 424      |\n",
      "|    fps             | 233      |\n",
      "|    time_elapsed    | 1083     |\n",
      "|    total_timesteps | 253120   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.7    |\n",
      "|    critic_loss     | 1.48     |\n",
      "|    ent_coef        | 0.0328   |\n",
      "|    ent_coef_loss   | -1.34    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 15194    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 819      |\n",
      "|    ep_rew_mean     | 29.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 428      |\n",
      "|    fps             | 233      |\n",
      "|    time_elapsed    | 1088     |\n",
      "|    total_timesteps | 254384   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.7    |\n",
      "|    critic_loss     | 1.93     |\n",
      "|    ent_coef        | 0.0324   |\n",
      "|    ent_coef_loss   | 1.94     |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 15273    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=256000, episode_reward=-22.66 +/- 24.46\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -22.7    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 256000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.1    |\n",
      "|    critic_loss     | 1.39     |\n",
      "|    ent_coef        | 0.0332   |\n",
      "|    ent_coef_loss   | -0.244   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 15374    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 819      |\n",
      "|    ep_rew_mean     | 30.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 432      |\n",
      "|    fps             | 230      |\n",
      "|    time_elapsed    | 1116     |\n",
      "|    total_timesteps | 257616   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.9    |\n",
      "|    critic_loss     | 1.49     |\n",
      "|    ent_coef        | 0.0336   |\n",
      "|    ent_coef_loss   | 0.572    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 15475    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 842      |\n",
      "|    ep_rew_mean     | 26.8     |\n",
      "| time/              |          |\n",
      "|    episodes        | 436      |\n",
      "|    fps             | 231      |\n",
      "|    time_elapsed    | 1120     |\n",
      "|    total_timesteps | 258976   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.7    |\n",
      "|    critic_loss     | 1.13     |\n",
      "|    ent_coef        | 0.033    |\n",
      "|    ent_coef_loss   | 0.0873   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 15560    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=264000, episode_reward=13.10 +/- 19.23\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 13.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 264000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.6    |\n",
      "|    critic_loss     | 2.24     |\n",
      "|    ent_coef        | 0.031    |\n",
      "|    ent_coef_loss   | -0.452   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 15874    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 844      |\n",
      "|    ep_rew_mean     | 28.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 440      |\n",
      "|    fps             | 229      |\n",
      "|    time_elapsed    | 1166     |\n",
      "|    total_timesteps | 267744   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.1    |\n",
      "|    critic_loss     | 7.78     |\n",
      "|    ent_coef        | 0.0297   |\n",
      "|    ent_coef_loss   | -1.24    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 16108    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 853      |\n",
      "|    ep_rew_mean     | 29.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 444      |\n",
      "|    fps             | 229      |\n",
      "|    time_elapsed    | 1175     |\n",
      "|    total_timesteps | 270096   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.8    |\n",
      "|    critic_loss     | 4.69     |\n",
      "|    ent_coef        | 0.0283   |\n",
      "|    ent_coef_loss   | 0.83     |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 16255    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=272000, episode_reward=4.43 +/- 11.08\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 4.43     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 272000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.7    |\n",
      "|    critic_loss     | 6        |\n",
      "|    ent_coef        | 0.029    |\n",
      "|    ent_coef_loss   | 0.3      |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 16374    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 867      |\n",
      "|    ep_rew_mean     | 25.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 448      |\n",
      "|    fps             | 227      |\n",
      "|    time_elapsed    | 1204     |\n",
      "|    total_timesteps | 273616   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.1    |\n",
      "|    critic_loss     | 1.28     |\n",
      "|    ent_coef        | 0.0293   |\n",
      "|    ent_coef_loss   | 0.955    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 16475    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 876      |\n",
      "|    ep_rew_mean     | 27.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 452      |\n",
      "|    fps             | 227      |\n",
      "|    time_elapsed    | 1208     |\n",
      "|    total_timesteps | 274976   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.1    |\n",
      "|    critic_loss     | 2.6      |\n",
      "|    ent_coef        | 0.0293   |\n",
      "|    ent_coef_loss   | 0.447    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 16560    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=280000, episode_reward=3.28 +/- 12.16\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 3.28     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 280000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.5    |\n",
      "|    critic_loss     | 2.85     |\n",
      "|    ent_coef        | 0.0311   |\n",
      "|    ent_coef_loss   | 0.0245   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 16874    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 892      |\n",
      "|    ep_rew_mean     | 25.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 456      |\n",
      "|    fps             | 226      |\n",
      "|    time_elapsed    | 1254     |\n",
      "|    total_timesteps | 283744   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -13.4    |\n",
      "|    critic_loss     | 3.15     |\n",
      "|    ent_coef        | 0.0298   |\n",
      "|    ent_coef_loss   | -0.861   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 17108    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 908      |\n",
      "|    ep_rew_mean     | 21.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 460      |\n",
      "|    fps             | 226      |\n",
      "|    time_elapsed    | 1263     |\n",
      "|    total_timesteps | 286096   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.6    |\n",
      "|    critic_loss     | 1.17     |\n",
      "|    ent_coef        | 0.0284   |\n",
      "|    ent_coef_loss   | -0.274   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 17255    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=288000, episode_reward=51.82 +/- 103.62\n",
      "Episode length: 843.60 +/- 312.80\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 844      |\n",
      "|    mean_reward     | 51.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 288000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.5    |\n",
      "|    critic_loss     | 8.36     |\n",
      "|    ent_coef        | 0.0281   |\n",
      "|    ent_coef_loss   | 0.242    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 17374    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 908      |\n",
      "|    ep_rew_mean     | 21.8     |\n",
      "| time/              |          |\n",
      "|    episodes        | 464      |\n",
      "|    fps             | 224      |\n",
      "|    time_elapsed    | 1290     |\n",
      "|    total_timesteps | 289616   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.9    |\n",
      "|    critic_loss     | 1.95     |\n",
      "|    ent_coef        | 0.027    |\n",
      "|    ent_coef_loss   | 0.513    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 17475    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 916      |\n",
      "|    ep_rew_mean     | 21.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 468      |\n",
      "|    fps             | 224      |\n",
      "|    time_elapsed    | 1293     |\n",
      "|    total_timesteps | 290976   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -10.8    |\n",
      "|    critic_loss     | 2.31     |\n",
      "|    ent_coef        | 0.0269   |\n",
      "|    ent_coef_loss   | 0.123    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 17560    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=296000, episode_reward=2.47 +/- 14.67\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.47     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 296000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.9    |\n",
      "|    critic_loss     | 1.29     |\n",
      "|    ent_coef        | 0.0275   |\n",
      "|    ent_coef_loss   | -0.413   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 17874    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 930      |\n",
      "|    ep_rew_mean     | 15.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 472      |\n",
      "|    fps             | 223      |\n",
      "|    time_elapsed    | 1339     |\n",
      "|    total_timesteps | 299744   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.2    |\n",
      "|    critic_loss     | 2.12     |\n",
      "|    ent_coef        | 0.0289   |\n",
      "|    ent_coef_loss   | 0.428    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 18108    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 930      |\n",
      "|    ep_rew_mean     | 16.7     |\n",
      "| time/              |          |\n",
      "|    episodes        | 476      |\n",
      "|    fps             | 224      |\n",
      "|    time_elapsed    | 1348     |\n",
      "|    total_timesteps | 302096   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.2    |\n",
      "|    critic_loss     | 8.38     |\n",
      "|    ent_coef        | 0.028    |\n",
      "|    ent_coef_loss   | -0.302   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 18255    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=304000, episode_reward=-24.13 +/- 15.13\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -24.1    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 304000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.5    |\n",
      "|    critic_loss     | 21.4     |\n",
      "|    ent_coef        | 0.027    |\n",
      "|    ent_coef_loss   | 0.151    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 18374    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 936      |\n",
      "|    ep_rew_mean     | 14       |\n",
      "| time/              |          |\n",
      "|    episodes        | 480      |\n",
      "|    fps             | 221      |\n",
      "|    time_elapsed    | 1378     |\n",
      "|    total_timesteps | 305616   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11      |\n",
      "|    critic_loss     | 3.23     |\n",
      "|    ent_coef        | 0.0272   |\n",
      "|    ent_coef_loss   | 0.566    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 18475    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 940      |\n",
      "|    ep_rew_mean     | 11       |\n",
      "| time/              |          |\n",
      "|    episodes        | 484      |\n",
      "|    fps             | 222      |\n",
      "|    time_elapsed    | 1381     |\n",
      "|    total_timesteps | 306976   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.14    |\n",
      "|    critic_loss     | 1.99     |\n",
      "|    ent_coef        | 0.0266   |\n",
      "|    ent_coef_loss   | 0.461    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 18560    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=312000, episode_reward=-13.02 +/- 5.36\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -13      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 312000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.69    |\n",
      "|    critic_loss     | 1.68     |\n",
      "|    ent_coef        | 0.0265   |\n",
      "|    ent_coef_loss   | -0.145   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 18874    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 938      |\n",
      "|    ep_rew_mean     | 12.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 488      |\n",
      "|    fps             | 220      |\n",
      "|    time_elapsed    | 1413     |\n",
      "|    total_timesteps | 312016   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.75    |\n",
      "|    critic_loss     | 2.33     |\n",
      "|    ent_coef        | 0.0265   |\n",
      "|    ent_coef_loss   | -0.771   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 18875    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 950      |\n",
      "|    ep_rew_mean     | 7.33     |\n",
      "| time/              |          |\n",
      "|    episodes        | 492      |\n",
      "|    fps             | 221      |\n",
      "|    time_elapsed    | 1433     |\n",
      "|    total_timesteps | 317696   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.5    |\n",
      "|    critic_loss     | 3.91     |\n",
      "|    ent_coef        | 0.0268   |\n",
      "|    ent_coef_loss   | -0.406   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 19230    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=320000, episode_reward=6.36 +/- 14.66\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 6.36     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 320000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.3    |\n",
      "|    critic_loss     | 1.1      |\n",
      "|    ent_coef        | 0.0269   |\n",
      "|    ent_coef_loss   | 0.957    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 19374    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 955      |\n",
      "|    ep_rew_mean     | 10.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 496      |\n",
      "|    fps             | 219      |\n",
      "|    time_elapsed    | 1464     |\n",
      "|    total_timesteps | 321616   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.9    |\n",
      "|    critic_loss     | 11.9     |\n",
      "|    ent_coef        | 0.0258   |\n",
      "|    ent_coef_loss   | -0.392   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 19475    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 952      |\n",
      "|    ep_rew_mean     | 11.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 500      |\n",
      "|    fps             | 219      |\n",
      "|    time_elapsed    | 1467     |\n",
      "|    total_timesteps | 322656   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -10.9    |\n",
      "|    critic_loss     | 2.09     |\n",
      "|    ent_coef        | 0.0251   |\n",
      "|    ent_coef_loss   | -0.111   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 19540    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 965      |\n",
      "|    ep_rew_mean     | 7        |\n",
      "| time/              |          |\n",
      "|    episodes        | 504      |\n",
      "|    fps             | 220      |\n",
      "|    time_elapsed    | 1481     |\n",
      "|    total_timesteps | 327136   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.58    |\n",
      "|    critic_loss     | 1.45     |\n",
      "|    ent_coef        | 0.0252   |\n",
      "|    ent_coef_loss   | -0.601   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 19820    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=328000, episode_reward=-12.87 +/- 8.58\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -12.9    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 328000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.41    |\n",
      "|    critic_loss     | 0.692    |\n",
      "|    ent_coef        | 0.0249   |\n",
      "|    ent_coef_loss   | -0.0134  |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 19874    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 958      |\n",
      "|    ep_rew_mean     | 9.29     |\n",
      "| time/              |          |\n",
      "|    episodes        | 508      |\n",
      "|    fps             | 218      |\n",
      "|    time_elapsed    | 1515     |\n",
      "|    total_timesteps | 331744   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.78    |\n",
      "|    critic_loss     | 1.58     |\n",
      "|    ent_coef        | 0.0249   |\n",
      "|    ent_coef_loss   | -1.58    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 20108    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 966      |\n",
      "|    ep_rew_mean     | 6.21     |\n",
      "| time/              |          |\n",
      "|    episodes        | 512      |\n",
      "|    fps             | 219      |\n",
      "|    time_elapsed    | 1524     |\n",
      "|    total_timesteps | 334384   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.1    |\n",
      "|    critic_loss     | 2.15     |\n",
      "|    ent_coef        | 0.0245   |\n",
      "|    ent_coef_loss   | -1.54    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 20273    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=336000, episode_reward=64.33 +/- 108.99\n",
      "Episode length: 869.20 +/- 261.60\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 869      |\n",
      "|    mean_reward     | 64.3     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 336000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.71    |\n",
      "|    critic_loss     | 1.56     |\n",
      "|    ent_coef        | 0.024    |\n",
      "|    ent_coef_loss   | 0.459    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 20374    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 966      |\n",
      "|    ep_rew_mean     | 6.99     |\n",
      "| time/              |          |\n",
      "|    episodes        | 516      |\n",
      "|    fps             | 217      |\n",
      "|    time_elapsed    | 1551     |\n",
      "|    total_timesteps | 338016   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.2    |\n",
      "|    critic_loss     | 7.82     |\n",
      "|    ent_coef        | 0.0233   |\n",
      "|    ent_coef_loss   | -1.08    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 20500    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 952      |\n",
      "|    ep_rew_mean     | 12.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 520      |\n",
      "|    fps             | 218      |\n",
      "|    time_elapsed    | 1564     |\n",
      "|    total_timesteps | 341760   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -10.1    |\n",
      "|    critic_loss     | 2.35     |\n",
      "|    ent_coef        | 0.0236   |\n",
      "|    ent_coef_loss   | 1.47     |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 20734    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=344000, episode_reward=96.37 +/- 119.74\n",
      "Episode length: 725.00 +/- 345.18\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 725      |\n",
      "|    mean_reward     | 96.4     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 344000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.57    |\n",
      "|    critic_loss     | 8        |\n",
      "|    ent_coef        | 0.0256   |\n",
      "|    ent_coef_loss   | 0.205    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 20874    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 952      |\n",
      "|    ep_rew_mean     | 12.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 524      |\n",
      "|    fps             | 217      |\n",
      "|    time_elapsed    | 1585     |\n",
      "|    total_timesteps | 344016   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11      |\n",
      "|    critic_loss     | 1.69     |\n",
      "|    ent_coef        | 0.0256   |\n",
      "|    ent_coef_loss   | -0.871   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 20875    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 946      |\n",
      "|    ep_rew_mean     | 15.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 528      |\n",
      "|    fps             | 218      |\n",
      "|    time_elapsed    | 1603     |\n",
      "|    total_timesteps | 349552   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.6    |\n",
      "|    critic_loss     | 1.01     |\n",
      "|    ent_coef        | 0.0259   |\n",
      "|    ent_coef_loss   | -0.0852  |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 21221    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=352000, episode_reward=-1.43 +/- 29.33\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -1.43    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 352000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11      |\n",
      "|    critic_loss     | 2.96     |\n",
      "|    ent_coef        | 0.0255   |\n",
      "|    ent_coef_loss   | 0.203    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 21374    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 946      |\n",
      "|    ep_rew_mean     | 16.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 532      |\n",
      "|    fps             | 216      |\n",
      "|    time_elapsed    | 1632     |\n",
      "|    total_timesteps | 353616   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.8    |\n",
      "|    critic_loss     | 3.78     |\n",
      "|    ent_coef        | 0.0261   |\n",
      "|    ent_coef_loss   | -0.145   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 21475    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 946      |\n",
      "|    ep_rew_mean     | 16.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 536      |\n",
      "|    fps             | 217      |\n",
      "|    time_elapsed    | 1646     |\n",
      "|    total_timesteps | 357504   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.01    |\n",
      "|    critic_loss     | 39.4     |\n",
      "|    ent_coef        | 0.0261   |\n",
      "|    ent_coef_loss   | 0.324    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 21718    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=360000, episode_reward=26.84 +/- 69.39\n",
      "Episode length: 982.20 +/- 35.60\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 982      |\n",
      "|    mean_reward     | 26.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 360000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -10      |\n",
      "|    critic_loss     | 1.84     |\n",
      "|    ent_coef        | 0.0258   |\n",
      "|    ent_coef_loss   | 0.876    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 21874    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 953      |\n",
      "|    ep_rew_mean     | 13.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 540      |\n",
      "|    fps             | 215      |\n",
      "|    time_elapsed    | 1671     |\n",
      "|    total_timesteps | 360016   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.84    |\n",
      "|    critic_loss     | 2.16     |\n",
      "|    ent_coef        | 0.0258   |\n",
      "|    ent_coef_loss   | -0.147   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 21875    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 950      |\n",
      "|    ep_rew_mean     | 16.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 544      |\n",
      "|    fps             | 215      |\n",
      "|    time_elapsed    | 1684     |\n",
      "|    total_timesteps | 363744   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.4    |\n",
      "|    critic_loss     | 6.96     |\n",
      "|    ent_coef        | 0.0248   |\n",
      "|    ent_coef_loss   | 1.61     |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 22108    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=368000, episode_reward=2.20 +/- 34.36\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.2      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 368000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.11    |\n",
      "|    critic_loss     | 1.8      |\n",
      "|    ent_coef        | 0.0244   |\n",
      "|    ent_coef_loss   | -0.275   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 22374    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 950      |\n",
      "|    ep_rew_mean     | 16.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 548      |\n",
      "|    fps             | 214      |\n",
      "|    time_elapsed    | 1724     |\n",
      "|    total_timesteps | 369616   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.47    |\n",
      "|    critic_loss     | 9.49     |\n",
      "|    ent_coef        | 0.0243   |\n",
      "|    ent_coef_loss   | 0.975    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 22475    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 950      |\n",
      "|    ep_rew_mean     | 15.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 552      |\n",
      "|    fps             | 214      |\n",
      "|    time_elapsed    | 1738     |\n",
      "|    total_timesteps | 373504   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.69    |\n",
      "|    critic_loss     | 6.7      |\n",
      "|    ent_coef        | 0.0257   |\n",
      "|    ent_coef_loss   | -0.457   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 22718    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 943      |\n",
      "|    ep_rew_mean     | 18.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 556      |\n",
      "|    fps             | 215      |\n",
      "|    time_elapsed    | 1744     |\n",
      "|    total_timesteps | 375200   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.23    |\n",
      "|    critic_loss     | 2.95     |\n",
      "|    ent_coef        | 0.0248   |\n",
      "|    ent_coef_loss   | 0.0556   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 22824    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=376000, episode_reward=53.79 +/- 101.60\n",
      "Episode length: 880.40 +/- 239.20\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 880      |\n",
      "|    mean_reward     | 53.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 376000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.89    |\n",
      "|    critic_loss     | 3.66     |\n",
      "|    ent_coef        | 0.0253   |\n",
      "|    ent_coef_loss   | 0.159    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 22874    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 930      |\n",
      "|    ep_rew_mean     | 23.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 560      |\n",
      "|    fps             | 213      |\n",
      "|    time_elapsed    | 1774     |\n",
      "|    total_timesteps | 379264   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -10.4    |\n",
      "|    critic_loss     | 0.968    |\n",
      "|    ent_coef        | 0.0238   |\n",
      "|    ent_coef_loss   | -0.372   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 23078    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 930      |\n",
      "|    ep_rew_mean     | 23.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 564      |\n",
      "|    fps             | 214      |\n",
      "|    time_elapsed    | 1782     |\n",
      "|    total_timesteps | 381552   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.46    |\n",
      "|    critic_loss     | 5.92     |\n",
      "|    ent_coef        | 0.023    |\n",
      "|    ent_coef_loss   | 0.0944   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 23221    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=384000, episode_reward=108.39 +/- 123.80\n",
      "Episode length: 778.00 +/- 281.13\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 778      |\n",
      "|    mean_reward     | 108      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 384000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.68    |\n",
      "|    critic_loss     | 50.7     |\n",
      "|    ent_coef        | 0.0225   |\n",
      "|    ent_coef_loss   | 0.136    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 23374    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 924      |\n",
      "|    ep_rew_mean     | 26.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 568      |\n",
      "|    fps             | 213      |\n",
      "|    time_elapsed    | 1807     |\n",
      "|    total_timesteps | 385616   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.53    |\n",
      "|    critic_loss     | 1.36     |\n",
      "|    ent_coef        | 0.022    |\n",
      "|    ent_coef_loss   | -0.599   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 23475    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 908      |\n",
      "|    ep_rew_mean     | 33.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 572      |\n",
      "|    fps             | 213      |\n",
      "|    time_elapsed    | 1814     |\n",
      "|    total_timesteps | 387696   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.67    |\n",
      "|    critic_loss     | 3.95     |\n",
      "|    ent_coef        | 0.0217   |\n",
      "|    ent_coef_loss   | 1        |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 23605    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 903      |\n",
      "|    ep_rew_mean     | 35.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 576      |\n",
      "|    fps             | 214      |\n",
      "|    time_elapsed    | 1821     |\n",
      "|    total_timesteps | 389936   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.61    |\n",
      "|    critic_loss     | 2.23     |\n",
      "|    ent_coef        | 0.0225   |\n",
      "|    ent_coef_loss   | 0.748    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 23745    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=392000, episode_reward=-18.53 +/- 17.83\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -18.5    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 392000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.05    |\n",
      "|    critic_loss     | 1.01     |\n",
      "|    ent_coef        | 0.0229   |\n",
      "|    ent_coef_loss   | -0.127   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 23874    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 897      |\n",
      "|    ep_rew_mean     | 38.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 580      |\n",
      "|    fps             | 213      |\n",
      "|    time_elapsed    | 1851     |\n",
      "|    total_timesteps | 395264   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.05    |\n",
      "|    critic_loss     | 28.3     |\n",
      "|    ent_coef        | 0.0242   |\n",
      "|    ent_coef_loss   | 1.79     |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 24078    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 897      |\n",
      "|    ep_rew_mean     | 39.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 584      |\n",
      "|    fps             | 214      |\n",
      "|    time_elapsed    | 1857     |\n",
      "|    total_timesteps | 397696   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.73    |\n",
      "|    critic_loss     | 2.58     |\n",
      "|    ent_coef        | 0.0255   |\n",
      "|    ent_coef_loss   | 0.465    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 24230    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=59.68 +/- 113.99\n",
      "Episode length: 859.00 +/- 282.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 859      |\n",
      "|    mean_reward     | 59.7     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 400000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.8    |\n",
      "|    critic_loss     | 1.33     |\n",
      "|    ent_coef        | 0.0263   |\n",
      "|    ent_coef_loss   | 0.577    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 24374    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 887      |\n",
      "|    ep_rew_mean     | 40.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 588      |\n",
      "|    fps             | 213      |\n",
      "|    time_elapsed    | 1879     |\n",
      "|    total_timesteps | 401616   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.65    |\n",
      "|    critic_loss     | 2.28     |\n",
      "|    ent_coef        | 0.0271   |\n",
      "|    ent_coef_loss   | 0.678    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 24475    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 881      |\n",
      "|    ep_rew_mean     | 42.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 592      |\n",
      "|    fps             | 214      |\n",
      "|    time_elapsed    | 1885     |\n",
      "|    total_timesteps | 403696   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.96    |\n",
      "|    critic_loss     | 1.07     |\n",
      "|    ent_coef        | 0.0256   |\n",
      "|    ent_coef_loss   | -1.75    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 24605    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 876      |\n",
      "|    ep_rew_mean     | 44.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 596      |\n",
      "|    fps             | 214      |\n",
      "|    time_elapsed    | 1891     |\n",
      "|    total_timesteps | 405936   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.31    |\n",
      "|    critic_loss     | 18.7     |\n",
      "|    ent_coef        | 0.0234   |\n",
      "|    ent_coef_loss   | 0.58     |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 24745    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=408000, episode_reward=-20.90 +/- 13.38\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -20.9    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 408000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.61    |\n",
      "|    critic_loss     | 0.975    |\n",
      "|    ent_coef        | 0.0221   |\n",
      "|    ent_coef_loss   | 0.0272   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 24874    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 877      |\n",
      "|    ep_rew_mean     | 43.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 600      |\n",
      "|    fps             | 214      |\n",
      "|    time_elapsed    | 1923     |\n",
      "|    total_timesteps | 411744   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.56    |\n",
      "|    critic_loss     | 1.93     |\n",
      "|    ent_coef        | 0.0226   |\n",
      "|    ent_coef_loss   | 0.327    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 25108    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 879      |\n",
      "|    ep_rew_mean     | 43.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 604      |\n",
      "|    fps             | 214      |\n",
      "|    time_elapsed    | 1936     |\n",
      "|    total_timesteps | 415968   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.81    |\n",
      "|    critic_loss     | 1.54     |\n",
      "|    ent_coef        | 0.0216   |\n",
      "|    ent_coef_loss   | 0.176    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 25372    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=416000, episode_reward=-3.63 +/- 149.30\n",
      "Episode length: 772.80 +/- 292.98\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 773      |\n",
      "|    mean_reward     | -3.63    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 416000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.56    |\n",
      "|    critic_loss     | 1.18     |\n",
      "|    ent_coef        | 0.0216   |\n",
      "|    ent_coef_loss   | -0.157   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 25374    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 878      |\n",
      "|    ep_rew_mean     | 39.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 608      |\n",
      "|    fps             | 214      |\n",
      "|    time_elapsed    | 1955     |\n",
      "|    total_timesteps | 418976   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.96    |\n",
      "|    critic_loss     | 1.07     |\n",
      "|    ent_coef        | 0.0239   |\n",
      "|    ent_coef_loss   | 0.268    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 25560    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 878      |\n",
      "|    ep_rew_mean     | 39.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 612      |\n",
      "|    fps             | 214      |\n",
      "|    time_elapsed    | 1962     |\n",
      "|    total_timesteps | 421280   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.34    |\n",
      "|    critic_loss     | 2.19     |\n",
      "|    ent_coef        | 0.0247   |\n",
      "|    ent_coef_loss   | 0.692    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 25704    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=424000, episode_reward=-6.34 +/- 142.08\n",
      "Episode length: 579.60 +/- 343.72\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 580      |\n",
      "|    mean_reward     | -6.34    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 424000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.21    |\n",
      "|    critic_loss     | 6.01     |\n",
      "|    ent_coef        | 0.0239   |\n",
      "|    ent_coef_loss   | -1.2     |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 25874    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 874      |\n",
      "|    ep_rew_mean     | 41       |\n",
      "| time/              |          |\n",
      "|    episodes        | 616      |\n",
      "|    fps             | 214      |\n",
      "|    time_elapsed    | 1976     |\n",
      "|    total_timesteps | 424016   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.11    |\n",
      "|    critic_loss     | 5.34     |\n",
      "|    ent_coef        | 0.0239   |\n",
      "|    ent_coef_loss   | 0.0125   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 25875    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 874      |\n",
      "|    ep_rew_mean     | 41.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 620      |\n",
      "|    fps             | 215      |\n",
      "|    time_elapsed    | 1995     |\n",
      "|    total_timesteps | 430096   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.16    |\n",
      "|    critic_loss     | 1.11     |\n",
      "|    ent_coef        | 0.0224   |\n",
      "|    ent_coef_loss   | -0.905   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 26255    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=432000, episode_reward=50.44 +/- 90.73\n",
      "Episode length: 928.80 +/- 89.11\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 929      |\n",
      "|    mean_reward     | 50.4     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 432000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.1     |\n",
      "|    critic_loss     | 0.918    |\n",
      "|    ent_coef        | 0.0233   |\n",
      "|    ent_coef_loss   | 0.13     |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 26374    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 874      |\n",
      "|    ep_rew_mean     | 40.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 624      |\n",
      "|    fps             | 214      |\n",
      "|    time_elapsed    | 2018     |\n",
      "|    total_timesteps | 432848   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.49    |\n",
      "|    critic_loss     | 3.72     |\n",
      "|    ent_coef        | 0.0239   |\n",
      "|    ent_coef_loss   | -0.127   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 26427    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 875      |\n",
      "|    ep_rew_mean     | 39.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 628      |\n",
      "|    fps             | 215      |\n",
      "|    time_elapsed    | 2026     |\n",
      "|    total_timesteps | 435664   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.56    |\n",
      "|    critic_loss     | 3.5      |\n",
      "|    ent_coef        | 0.0229   |\n",
      "|    ent_coef_loss   | -1.6     |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 26603    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 867      |\n",
      "|    ep_rew_mean     | 40.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 632      |\n",
      "|    fps             | 215      |\n",
      "|    time_elapsed    | 2030     |\n",
      "|    total_timesteps | 437280   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.9     |\n",
      "|    critic_loss     | 0.98     |\n",
      "|    ent_coef        | 0.0228   |\n",
      "|    ent_coef_loss   | 0.678    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 26704    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=440000, episode_reward=37.13 +/- 110.58\n",
      "Episode length: 881.40 +/- 237.20\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 881      |\n",
      "|    mean_reward     | 37.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 440000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.85    |\n",
      "|    critic_loss     | 0.85     |\n",
      "|    ent_coef        | 0.023    |\n",
      "|    ent_coef_loss   | 1.07     |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 26874    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 861      |\n",
      "|    ep_rew_mean     | 44.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 636      |\n",
      "|    fps             | 215      |\n",
      "|    time_elapsed    | 2062     |\n",
      "|    total_timesteps | 444352   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.68    |\n",
      "|    critic_loss     | 1.37     |\n",
      "|    ent_coef        | 0.0251   |\n",
      "|    ent_coef_loss   | 0.174    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 27146    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 861      |\n",
      "|    ep_rew_mean     | 44.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 640      |\n",
      "|    fps             | 215      |\n",
      "|    time_elapsed    | 2074     |\n",
      "|    total_timesteps | 447968   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.29    |\n",
      "|    critic_loss     | 2.33     |\n",
      "|    ent_coef        | 0.0251   |\n",
      "|    ent_coef_loss   | 0.648    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 27372    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=448000, episode_reward=-22.85 +/- 17.21\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -22.8    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 448000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.74    |\n",
      "|    critic_loss     | 4.41     |\n",
      "|    ent_coef        | 0.0251   |\n",
      "|    ent_coef_loss   | 0.349    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 27374    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 863      |\n",
      "|    ep_rew_mean     | 42       |\n",
      "| time/              |          |\n",
      "|    episodes        | 644      |\n",
      "|    fps             | 214      |\n",
      "|    time_elapsed    | 2098     |\n",
      "|    total_timesteps | 450976   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.34    |\n",
      "|    critic_loss     | 1.29     |\n",
      "|    ent_coef        | 0.0247   |\n",
      "|    ent_coef_loss   | 0.253    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 27560    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 863      |\n",
      "|    ep_rew_mean     | 42.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 648      |\n",
      "|    fps             | 215      |\n",
      "|    time_elapsed    | 2104     |\n",
      "|    total_timesteps | 453280   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.79    |\n",
      "|    critic_loss     | 4.34     |\n",
      "|    ent_coef        | 0.0249   |\n",
      "|    ent_coef_loss   | 0.414    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 27704    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=456000, episode_reward=167.34 +/- 75.32\n",
      "Episode length: 644.80 +/- 198.25\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 645      |\n",
      "|    mean_reward     | 167      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 456000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.11    |\n",
      "|    critic_loss     | 12.4     |\n",
      "|    ent_coef        | 0.0286   |\n",
      "|    ent_coef_loss   | 0.739    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 27874    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 853      |\n",
      "|    ep_rew_mean     | 48.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 652      |\n",
      "|    fps             | 215      |\n",
      "|    time_elapsed    | 2118     |\n",
      "|    total_timesteps | 456016   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.88    |\n",
      "|    critic_loss     | 1.82     |\n",
      "|    ent_coef        | 0.0286   |\n",
      "|    ent_coef_loss   | 0.314    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 27875    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 852      |\n",
      "|    ep_rew_mean     | 51.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 656      |\n",
      "|    fps             | 216      |\n",
      "|    time_elapsed    | 2129     |\n",
      "|    total_timesteps | 460176   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.85    |\n",
      "|    critic_loss     | 5.69     |\n",
      "|    ent_coef        | 0.0265   |\n",
      "|    ent_coef_loss   | 0.565    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 28135    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=464000, episode_reward=48.14 +/- 118.44\n",
      "Episode length: 864.40 +/- 271.20\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 864      |\n",
      "|    mean_reward     | 48.1     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 464000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -10.1    |\n",
      "|    critic_loss     | 1.75     |\n",
      "|    ent_coef        | 0.0246   |\n",
      "|    ent_coef_loss   | 1.52     |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 28374    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 857      |\n",
      "|    ep_rew_mean     | 50.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 660      |\n",
      "|    fps             | 215      |\n",
      "|    time_elapsed    | 2154     |\n",
      "|    total_timesteps | 464848   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.8     |\n",
      "|    critic_loss     | 1.25     |\n",
      "|    ent_coef        | 0.025    |\n",
      "|    ent_coef_loss   | 0.42     |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 28427    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 852      |\n",
      "|    ep_rew_mean     | 53.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 664      |\n",
      "|    fps             | 216      |\n",
      "|    time_elapsed    | 2161     |\n",
      "|    total_timesteps | 466976   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.89    |\n",
      "|    critic_loss     | 1.21     |\n",
      "|    ent_coef        | 0.0241   |\n",
      "|    ent_coef_loss   | 0.553    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 28560    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 847      |\n",
      "|    ep_rew_mean     | 55.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 668      |\n",
      "|    fps             | 216      |\n",
      "|    time_elapsed    | 2168     |\n",
      "|    total_timesteps | 469744   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.37    |\n",
      "|    critic_loss     | 2.28     |\n",
      "|    ent_coef        | 0.0238   |\n",
      "|    ent_coef_loss   | -0.245   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 28733    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 859      |\n",
      "|    ep_rew_mean     | 52.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 672      |\n",
      "|    fps             | 216      |\n",
      "|    time_elapsed    | 2172     |\n",
      "|    total_timesteps | 471328   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.39    |\n",
      "|    critic_loss     | 5.96     |\n",
      "|    ent_coef        | 0.0234   |\n",
      "|    ent_coef_loss   | -0.532   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 28832    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=472000, episode_reward=163.87 +/- 134.60\n",
      "Episode length: 630.40 +/- 306.05\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 630      |\n",
      "|    mean_reward     | 164      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 472000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.07    |\n",
      "|    critic_loss     | 4.81     |\n",
      "|    ent_coef        | 0.0233   |\n",
      "|    ent_coef_loss   | -0.0781  |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 28874    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 850      |\n",
      "|    ep_rew_mean     | 57.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 676      |\n",
      "|    fps             | 217      |\n",
      "|    time_elapsed    | 2191     |\n",
      "|    total_timesteps | 476720   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.23    |\n",
      "|    critic_loss     | 4.34     |\n",
      "|    ent_coef        | 0.0228   |\n",
      "|    ent_coef_loss   | -0.889   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 29169    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=133.60 +/- 118.33\n",
      "Episode length: 787.80 +/- 264.47\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 788      |\n",
      "|    mean_reward     | 134      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 480000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.46    |\n",
      "|    critic_loss     | 1.03     |\n",
      "|    ent_coef        | 0.023    |\n",
      "|    ent_coef_loss   | -1.01    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 29374    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 850      |\n",
      "|    ep_rew_mean     | 59       |\n",
      "| time/              |          |\n",
      "|    episodes        | 680      |\n",
      "|    fps             | 217      |\n",
      "|    time_elapsed    | 2213     |\n",
      "|    total_timesteps | 481120   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.3     |\n",
      "|    critic_loss     | 9.4      |\n",
      "|    ent_coef        | 0.023    |\n",
      "|    ent_coef_loss   | -0.0635  |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 29444    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 834      |\n",
      "|    ep_rew_mean     | 66.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 684      |\n",
      "|    fps             | 217      |\n",
      "|    time_elapsed    | 2216     |\n",
      "|    total_timesteps | 481840   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.35    |\n",
      "|    critic_loss     | 1.24     |\n",
      "|    ent_coef        | 0.0231   |\n",
      "|    ent_coef_loss   | 1.3      |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 29489    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 844      |\n",
      "|    ep_rew_mean     | 64.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 688      |\n",
      "|    fps             | 218      |\n",
      "|    time_elapsed    | 2226     |\n",
      "|    total_timesteps | 485360   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.52    |\n",
      "|    critic_loss     | 3.4      |\n",
      "|    ent_coef        | 0.0231   |\n",
      "|    ent_coef_loss   | 0.41     |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 29709    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 842      |\n",
      "|    ep_rew_mean     | 66.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 692      |\n",
      "|    fps             | 218      |\n",
      "|    time_elapsed    | 2229     |\n",
      "|    total_timesteps | 486704   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.26    |\n",
      "|    critic_loss     | 2.22     |\n",
      "|    ent_coef        | 0.023    |\n",
      "|    ent_coef_loss   | 1.41     |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 29793    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=488000, episode_reward=39.72 +/- 71.41\n",
      "Episode length: 934.20 +/- 131.60\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 934      |\n",
      "|    mean_reward     | 39.7     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 488000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.16    |\n",
      "|    critic_loss     | 7.47     |\n",
      "|    ent_coef        | 0.0242   |\n",
      "|    ent_coef_loss   | -0.477   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 29874    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 838      |\n",
      "|    ep_rew_mean     | 70.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 696      |\n",
      "|    fps             | 217      |\n",
      "|    time_elapsed    | 2249     |\n",
      "|    total_timesteps | 488560   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.07    |\n",
      "|    critic_loss     | 2.04     |\n",
      "|    ent_coef        | 0.024    |\n",
      "|    ent_coef_loss   | -0.585   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 29909    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=496000, episode_reward=92.39 +/- 134.35\n",
      "Episode length: 790.20 +/- 261.24\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 790      |\n",
      "|    mean_reward     | 92.4     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 496000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.6     |\n",
      "|    critic_loss     | 5.81     |\n",
      "|    ent_coef        | 0.0218   |\n",
      "|    ent_coef_loss   | 0.909    |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 30374    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 836      |\n",
      "|    ep_rew_mean     | 73.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 700      |\n",
      "|    fps             | 217      |\n",
      "|    time_elapsed    | 2282     |\n",
      "|    total_timesteps | 496848   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.57    |\n",
      "|    critic_loss     | 5.11     |\n",
      "|    ent_coef        | 0.0222   |\n",
      "|    ent_coef_loss   | 0.0175   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 30427    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 834      |\n",
      "|    ep_rew_mean     | 74.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 704      |\n",
      "|    fps             | 217      |\n",
      "|    time_elapsed    | 2285     |\n",
      "|    total_timesteps | 497840   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.38    |\n",
      "|    critic_loss     | 3.55     |\n",
      "|    ent_coef        | 0.0221   |\n",
      "|    ent_coef_loss   | -0.347   |\n",
      "|    learning_rate   | 0.00073  |\n",
      "|    n_updates       | 30489    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.sac.sac.SAC at 0x25223967ca0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=int(5e5), callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"data/policies/LunarLanderContinuous-v2#sac#training\")\n",
    "del model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
